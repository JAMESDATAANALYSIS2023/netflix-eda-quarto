[
  {
    "objectID": "Six-Sigma-Projects/six-sigma-projects.html",
    "href": "Six-Sigma-Projects/six-sigma-projects.html",
    "title": "Six Sigma Projects",
    "section": "",
    "text": "About this site"
  },
  {
    "objectID": "Six-Sigma-Projects/index.html",
    "href": "Six-Sigma-Projects/index.html",
    "title": "Six Sigm Projects",
    "section": "",
    "text": "Project 1\nProject 2"
  },
  {
    "objectID": "Six-Sigma-Projects/index.html#my-six-sigma-projects.",
    "href": "Six-Sigma-Projects/index.html#my-six-sigma-projects.",
    "title": "Six Sigm Projects",
    "section": "",
    "text": "Project 1\nProject 2"
  },
  {
    "objectID": "R-projects/r-projects-2.html",
    "href": "R-projects/r-projects-2.html",
    "title": "R Projects",
    "section": "",
    "text": "About this site\n\nsummary(mtcars)\n\n      mpg             cyl             disp             hp       \n Min.   :10.40   Min.   :4.000   Min.   : 71.1   Min.   : 52.0  \n 1st Qu.:15.43   1st Qu.:4.000   1st Qu.:120.8   1st Qu.: 96.5  \n Median :19.20   Median :6.000   Median :196.3   Median :123.0  \n Mean   :20.09   Mean   :6.188   Mean   :230.7   Mean   :146.7  \n 3rd Qu.:22.80   3rd Qu.:8.000   3rd Qu.:326.0   3rd Qu.:180.0  \n Max.   :33.90   Max.   :8.000   Max.   :472.0   Max.   :335.0  \n      drat             wt             qsec             vs        \n Min.   :2.760   Min.   :1.513   Min.   :14.50   Min.   :0.0000  \n 1st Qu.:3.080   1st Qu.:2.581   1st Qu.:16.89   1st Qu.:0.0000  \n Median :3.695   Median :3.325   Median :17.71   Median :0.0000  \n Mean   :3.597   Mean   :3.217   Mean   :17.85   Mean   :0.4375  \n 3rd Qu.:3.920   3rd Qu.:3.610   3rd Qu.:18.90   3rd Qu.:1.0000  \n Max.   :4.930   Max.   :5.424   Max.   :22.90   Max.   :1.0000  \n       am              gear            carb      \n Min.   :0.0000   Min.   :3.000   Min.   :1.000  \n 1st Qu.:0.0000   1st Qu.:3.000   1st Qu.:2.000  \n Median :0.0000   Median :4.000   Median :2.000  \n Mean   :0.4062   Mean   :3.688   Mean   :2.812  \n 3rd Qu.:1.0000   3rd Qu.:4.000   3rd Qu.:4.000  \n Max.   :1.0000   Max.   :5.000   Max.   :8.000  \n\n1 + 1\n\n[1] 2"
  },
  {
    "objectID": "python-projects/python-projects.html",
    "href": "python-projects/python-projects.html",
    "title": "Python Projects",
    "section": "",
    "text": "librara\nlibrary(reticulate)\n\n# Replace this with your actual Python path if it's different\nuse_python(\"C:/Users/jgpet/AppData/Local/Programs/Python/Python312/python.exe\", required = TRUE)\nProject: Customer Insights Using COIL 2000 & Bank Marketing Data\n‚ÄúUnlocking Business Value through Predictive Analytics‚Äù\nIn today‚Äôs data-driven economy, financial and insurance companies must harness the power of analytics to understand customer behavior, enhance retention, and optimize marketing strategies. This project applies supervised machine learning and clustering techniques to two real-world datasets using Python and its rich ecosystem of libraries.\nüß∞ Tools & Libraries\nThe analysis leverages the following Python libraries:\n\npandas for data manipulation and preprocessing\nnumpy for numerical operations\nmatplotlib and seaborn for visualizations\nscikit-learn for classification models and clustering (e.g., KMeans)\nplotly for interactive visuals\nimbalanced-learn for handling class imbalance (if applicable)\n\nBank Marketing Dataset\nSource: UCI Machine Learning Repository\nDescription: Collected from a Portuguese banking institution, this dataset records results of a direct marketing campaign aimed at promoting term deposits. It includes features like age, job, marital status, previous contact outcomes, and a target variable indicating subscription.\nüéØ Project Objectives\n\nPredict customer responses to marketing campaigns\nIdentify high-value segments using clustering algorithms\nReduce customer churn through classification models\nVisualize trends and feature relationships through interactive dashboards\n\n\n# This code imports the os as a module to interact with the operating system\nimport os\n\n# To display the current working directory to identity where Python is excecuting the scripts.\nprint(\"Current working directory:\", os.getcwd())\n\nCurrent working directory: C:\\Users\\jgpet\\OneDrive\\Desktop\\DATA ANALYST\\Data Analytic Portfolio\\Lets make Musicupdated\\python-projects\n\n\nfff\n\nfrom ucimlrepo import fetch_ucirepo \n  \n# fetch dataset \nbank_marketing = fetch_ucirepo(id=222) \n  \n# data (as pandas dataframes) \nX = bank_marketing.data.features \ny = bank_marketing.data.targets \n  \n# metadata \nprint(bank_marketing.metadata) \n  \n# variable information \nprint(bank_marketing.variables) \n\n{'uci_id': 222, 'name': 'Bank Marketing', 'repository_url': 'https://archive.ics.uci.edu/dataset/222/bank+marketing', 'data_url': 'https://archive.ics.uci.edu/static/public/222/data.csv', 'abstract': 'The data is related with direct marketing campaigns (phone calls) of a Portuguese banking institution. The classification goal is to predict if the client will subscribe a term deposit (variable y).', 'area': 'Business', 'tasks': ['Classification'], 'characteristics': ['Multivariate'], 'num_instances': 45211, 'num_features': 16, 'feature_types': ['Categorical', 'Integer'], 'demographics': ['Age', 'Occupation', 'Marital Status', 'Education Level'], 'target_col': ['y'], 'index_col': None, 'has_missing_values': 'yes', 'missing_values_symbol': 'NaN', 'year_of_dataset_creation': 2014, 'last_updated': 'Fri Aug 18 2023', 'dataset_doi': '10.24432/C5K306', 'creators': ['S. Moro', 'P. Rita', 'P. Cortez'], 'intro_paper': {'ID': 277, 'type': 'NATIVE', 'title': 'A data-driven approach to predict the success of bank telemarketing', 'authors': 'S√©rgio Moro, P. Cortez, P. Rita', 'venue': 'Decision Support Systems', 'year': 2014, 'journal': None, 'DOI': '10.1016/j.dss.2014.03.001', 'URL': 'https://www.semanticscholar.org/paper/cab86052882d126d43f72108c6cb41b295cc8a9e', 'sha': None, 'corpus': None, 'arxiv': None, 'mag': None, 'acl': None, 'pmid': None, 'pmcid': None}, 'additional_info': {'summary': \"The data is related with direct marketing campaigns of a Portuguese banking institution. The marketing campaigns were based on phone calls. Often, more than one contact to the same client was required, in order to access if the product (bank term deposit) would be ('yes') or not ('no') subscribed. \\n\\nThere are four datasets: \\n1) bank-additional-full.csv with all examples (41188) and 20 inputs, ordered by date (from May 2008 to November 2010), very close to the data analyzed in [Moro et al., 2014]\\n2) bank-additional.csv with 10% of the examples (4119), randomly selected from 1), and 20 inputs.\\n3) bank-full.csv with all examples and 17 inputs, ordered by date (older version of this dataset with less inputs). \\n4) bank.csv with 10% of the examples and 17 inputs, randomly selected from 3 (older version of this dataset with less inputs). \\nThe smallest datasets are provided to test more computationally demanding machine learning algorithms (e.g., SVM). \\n\\nThe classification goal is to predict if the client will subscribe (yes/no) a term deposit (variable y).\", 'purpose': None, 'funded_by': None, 'instances_represent': None, 'recommended_data_splits': None, 'sensitive_data': None, 'preprocessing_description': None, 'variable_info': 'Input variables:\\n   # bank client data:\\n   1 - age (numeric)\\n   2 - job : type of job (categorical: \"admin.\",\"unknown\",\"unemployed\",\"management\",\"housemaid\",\"entrepreneur\",\"student\",\\n                                       \"blue-collar\",\"self-employed\",\"retired\",\"technician\",\"services\") \\n   3 - marital : marital status (categorical: \"married\",\"divorced\",\"single\"; note: \"divorced\" means divorced or widowed)\\n   4 - education (categorical: \"unknown\",\"secondary\",\"primary\",\"tertiary\")\\n   5 - default: has credit in default? (binary: \"yes\",\"no\")\\n   6 - balance: average yearly balance, in euros (numeric) \\n   7 - housing: has housing loan? (binary: \"yes\",\"no\")\\n   8 - loan: has personal loan? (binary: \"yes\",\"no\")\\n   # related with the last contact of the current campaign:\\n   9 - contact: contact communication type (categorical: \"unknown\",\"telephone\",\"cellular\") \\n  10 - day: last contact day of the month (numeric)\\n  11 - month: last contact month of year (categorical: \"jan\", \"feb\", \"mar\", ..., \"nov\", \"dec\")\\n  12 - duration: last contact duration, in seconds (numeric)\\n   # other attributes:\\n  13 - campaign: number of contacts performed during this campaign and for this client (numeric, includes last contact)\\n  14 - pdays: number of days that passed by after the client was last contacted from a previous campaign (numeric, -1 means client was not previously contacted)\\n  15 - previous: number of contacts performed before this campaign and for this client (numeric)\\n  16 - poutcome: outcome of the previous marketing campaign (categorical: \"unknown\",\"other\",\"failure\",\"success\")\\n\\n  Output variable (desired target):\\n  17 - y - has the client subscribed a term deposit? (binary: \"yes\",\"no\")\\n', 'citation': None}}\n           name     role         type      demographic  \\\n0           age  Feature      Integer              Age   \n1           job  Feature  Categorical       Occupation   \n2       marital  Feature  Categorical   Marital Status   \n3     education  Feature  Categorical  Education Level   \n4       default  Feature       Binary             None   \n5       balance  Feature      Integer             None   \n6       housing  Feature       Binary             None   \n7          loan  Feature       Binary             None   \n8       contact  Feature  Categorical             None   \n9   day_of_week  Feature         Date             None   \n10        month  Feature         Date             None   \n11     duration  Feature      Integer             None   \n12     campaign  Feature      Integer             None   \n13        pdays  Feature      Integer             None   \n14     previous  Feature      Integer             None   \n15     poutcome  Feature  Categorical             None   \n16            y   Target       Binary             None   \n\n                                          description  units missing_values  \n0                                                None   None             no  \n1   type of job (categorical: 'admin.','blue-colla...   None             no  \n2   marital status (categorical: 'divorced','marri...   None             no  \n3   (categorical: 'basic.4y','basic.6y','basic.9y'...   None             no  \n4                              has credit in default?   None             no  \n5                              average yearly balance  euros             no  \n6                                   has housing loan?   None             no  \n7                                  has personal loan?   None             no  \n8   contact communication type (categorical: 'cell...   None            yes  \n9                        last contact day of the week   None             no  \n10  last contact month of year (categorical: 'jan'...   None             no  \n11   last contact duration, in seconds (numeric). ...   None             no  \n12  number of contacts performed during this campa...   None             no  \n13  number of days that passed by after the client...   None            yes  \n14  number of contacts performed before this campa...   None             no  \n15  outcome of the previous marketing campaign (ca...   None            yes  \n16          has the client subscribed a term deposit?   None             no  \n\n\nNow that the working directory is set to the correct location we can load the files for processing.\n\nimport pandas as pd\n\ndf = pd.read_csv(\"bank-full.csv\")\ndf.head()\n\n\n\n\n\n\n\n\nage;\"job\";\"marital\";\"education\";\"default\";\"balance\";\"housing\";\"loan\";\"contact\";\"day\";\"month\";\"duration\";\"campaign\";\"pdays\";\"previous\";\"poutcome\";\"y\"\n\n\n\n\n0\n58;\"management\";\"married\";\"tertiary\";\"no\";2143...\n\n\n1\n44;\"technician\";\"single\";\"secondary\";\"no\";29;\"...\n\n\n2\n33;\"entrepreneur\";\"married\";\"secondary\";\"no\";2...\n\n\n3\n47;\"blue-collar\";\"married\";\"unknown\";\"no\";1506...\n\n\n4\n33;\"unknown\";\"single\";\"unknown\";\"no\";1;\"no\";\"n...\n\n\n\n\n\n\n\ndddd\n\ndf\n\n\n\n\n\n\n\n\nage;\"job\";\"marital\";\"education\";\"default\";\"balance\";\"housing\";\"loan\";\"contact\";\"day\";\"month\";\"duration\";\"campaign\";\"pdays\";\"previous\";\"poutcome\";\"y\"\n\n\n\n\n0\n58;\"management\";\"married\";\"tertiary\";\"no\";2143...\n\n\n1\n44;\"technician\";\"single\";\"secondary\";\"no\";29;\"...\n\n\n2\n33;\"entrepreneur\";\"married\";\"secondary\";\"no\";2...\n\n\n3\n47;\"blue-collar\";\"married\";\"unknown\";\"no\";1506...\n\n\n4\n33;\"unknown\";\"single\";\"unknown\";\"no\";1;\"no\";\"n...\n\n\n...\n...\n\n\n45206\n51;\"technician\";\"married\";\"tertiary\";\"no\";825;...\n\n\n45207\n71;\"retired\";\"divorced\";\"primary\";\"no\";1729;\"n...\n\n\n45208\n72;\"retired\";\"married\";\"secondary\";\"no\";5715;\"...\n\n\n45209\n57;\"blue-collar\";\"married\";\"secondary\";\"no\";66...\n\n\n45210\n37;\"entrepreneur\";\"married\";\"secondary\";\"no\";2...\n\n\n\n\n45211 rows √ó 1 columns"
  },
  {
    "objectID": "python-projects/python-projects-3.html",
    "href": "python-projects/python-projects-3.html",
    "title": "Water Pump Functionality Prediction",
    "section": "",
    "text": "library(reticulate)\nuse_python(\"C:/Users/jgpet/AppData/Local/Programs/Python/Python312/python.exe\", required = TRUE)"
  },
  {
    "objectID": "python-projects/python-projects-3.html#project-overview",
    "href": "python-projects/python-projects-3.html#project-overview",
    "title": "Water Pump Functionality Prediction",
    "section": "Project Overview",
    "text": "Project Overview\nThis project explores the use of machine learning to predict the functionality status of water pumps in rural areas. The dataset includes features such as water source, pump type, distance to town, population served, and funding organization.\nGoal: Build a predictive model to determine whether a water pump is functional or non-functional.\n\n# Import Libraries\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport os\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import classification_report, confusion_matrix\nfrom statsmodels.stats.outliers_influence import variance_inflation_factor\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Dense, Dropout\nfrom tensorflow.keras.optimizers import Adam\nfrom tensorflow.keras.callbacks import EarlyStopping"
  },
  {
    "objectID": "python-projects/python-projects-3.html#set-and-verify-working-directory",
    "href": "python-projects/python-projects-3.html#set-and-verify-working-directory",
    "title": "Water Pump Functionality Prediction",
    "section": "Set and Verify Working Directory",
    "text": "Set and Verify Working Directory\nBefore loading the dataset, we confirm the current working directory and change it to the location where the cleaned data file is stored.\n\n# Set and Verify Working Directory\n\n# PYthon library\nimport os\n\nprint(\"Current working directory:\", os.getcwd())\n\nos.chdir(r\"C:\\Users\\jgpet\\OneDrive\\Desktop\\Gradiate school\\2025\\DSCI 5240\\Final Project\")\nprint(\"New working directory:\", os.getcwd())"
  },
  {
    "objectID": "python-projects/python-projects-3.html#load-dataset",
    "href": "python-projects/python-projects-3.html#load-dataset",
    "title": "Water Pump Functionality Prediction",
    "section": "Load Dataset",
    "text": "Load Dataset\nSet the working directory and load the cleaned dataset into memory.\n\n# Load Dataset\nFinal_project = pd.read_csv(\"Final_project_clean.csv\", header=0)\npd.set_option(\"display.max_columns\", None)"
  },
  {
    "objectID": "python-projects/python-projects-3.html#handle-outliers",
    "href": "python-projects/python-projects-3.html#handle-outliers",
    "title": "Water Pump Functionality Prediction",
    "section": "Handle Outliers",
    "text": "Handle Outliers\nUse the IQR method to detect and cap outliers in numerical features: - Distance to Nearest Town - Population Served - Water Pump Age\n\n# Outlier Detection & Capping\nnum_cols = ['Distance to Nearest Town', 'Population Served', 'Water Pump Age']\n\nfor col in num_cols:\n    Q1 = Final_project[col].quantile(0.25)\n    Q3 = Final_project[col].quantile(0.75)\n    IQR = Q3 - Q1\n    lower_bound = Q1 - 1.5 * IQR\n    upper_bound = Q3 + 1.5 * IQR\n    Final_project[col] = Final_project[col].clip(lower=lower_bound, upper=upper_bound)\n\n# Clip distance values below 0 to 0\nFinal_project['Distance to Nearest Town'] = Final_project['Distance to Nearest Town'].clip(lower=0)"
  },
  {
    "objectID": "python-projects/python-projects-3.html#encode-categorical-variables",
    "href": "python-projects/python-projects-3.html#encode-categorical-variables",
    "title": "Water Pump Functionality Prediction",
    "section": "üî§ Encode Categorical Variables",
    "text": "üî§ Encode Categorical Variables\n\nBinary encoding for Water Quality, Payment Type, and Functioning Status\n\nOne-hot encoding for Water Source Type, Funder, Pump Type\n\n\n# Encode Categorical Variables\nbinary_map = {\n    'Water Quality': {'Clean': 0, 'Contaminated': 1},\n    'Payment Type': {'Free': 0, 'Pay per use': 1},\n    'Functioning Status': {'Not Functioning': 0, 'Functioning': 1}\n}\ndf_encoded = Final_project.replace(binary_map)\ncategorical_cols = ['Water Source Type', 'Funder', 'Pump Type']\ndf_encoded = pd.get_dummies(df_encoded, columns=categorical_cols, drop_first=True)\ndf_encoded = df_encoded.astype(int)"
  },
  {
    "objectID": "python-projects/python-projects-3.html#variance-inflation-factor-vif",
    "href": "python-projects/python-projects-3.html#variance-inflation-factor-vif",
    "title": "Water Pump Functionality Prediction",
    "section": "üßÆ Variance Inflation Factor (VIF)",
    "text": "üßÆ Variance Inflation Factor (VIF)\nDetect multicollinearity and remove features with VIF &gt; 10 to improve model interpretability.\n\n# Define X and y\ny = df_encoded['Functioning Status']\nX = df_encoded.drop(columns='Functioning Status')\n\n# VIF for Feature Selection\nX_vif = X.astype(float)\nvif_data = pd.DataFrame()\nvif_data['Feature'] = X_vif.columns\nvif_data['VIF'] = [variance_inflation_factor(X_vif.values, i) for i in range(X_vif.shape[1])]\n\n# Drop high VIF features\nhigh_vif_features = ['Installation Year', 'Population Served']\nX_reduced = X.drop(columns=high_vif_features)"
  },
  {
    "objectID": "python-projects/python-projects-3.html#feature-scaling",
    "href": "python-projects/python-projects-3.html#feature-scaling",
    "title": "Water Pump Functionality Prediction",
    "section": "üìè Feature Scaling",
    "text": "üìè Feature Scaling\nStandardize numerical features to ensure they contribute equally to the model.\n\n# Scaling\n\nscaler = StandardScaler()\nnumeric_cols = ['Distance to Nearest Town', 'Water Pump Age']\nX_scaled = X_reduced.copy()\nX_scaled[numeric_cols] = scaler.fit_transform(X_scaled[numeric_cols])"
  },
  {
    "objectID": "python-projects/python-projects-3.html#neural-network-model-keras",
    "href": "python-projects/python-projects-3.html#neural-network-model-keras",
    "title": "Water Pump Functionality Prediction",
    "section": "ü§ñ Neural Network Model (Keras)",
    "text": "ü§ñ Neural Network Model (Keras)\nTrain a neural network to classify water pumps as functioning or not.\n\n# Train-Test Split\nX_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.3, random_state=4)\n\n\n# Build Neural Network\nmodel = Sequential([\n    Dense(16, activation='relu', input_shape=(X_train.shape[1],)),\n    Dropout(0.3),\n    Dense(12, activation='relu'),\n    Dropout(0.3),\n    Dense(6, activation='relu'),\n    Dropout(0.3),\n    Dense(1, activation='sigmoid')\n])\n\n\nmodel.compile(optimizer=Adam(learning_rate=0.001), loss='binary_crossentropy', metrics=['accuracy'])\nearly_stop = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n\n# Train Model\nhistory = model.fit(\n    X_train, y_train,\n    validation_split=0.2,\n    epochs=50,\n    batch_size=32,\n    callbacks=[early_stop],\n    verbose=1\n)"
  },
  {
    "objectID": "python-projects/python-projects-3.html#model-evaluation",
    "href": "python-projects/python-projects-3.html#model-evaluation",
    "title": "Water Pump Functionality Prediction",
    "section": "üìà Model Evaluation",
    "text": "üìà Model Evaluation\nDisplay classification report and confusion matrix to evaluate performance.\n\n# Evaluate Model\ny_pred = (model.predict(X_test) &gt; 0.5).astype(\"int32\")\nprint(\"\\nClassification Report:\\n\", classification_report(y_test, y_pred))\nprint(\"\\nConfusion Matrix:\\n\", confusion_matrix(y_test, y_pred))"
  },
  {
    "objectID": "python-projects/python-projects-3.html#training-history",
    "href": "python-projects/python-projects-3.html#training-history",
    "title": "Water Pump Functionality Prediction",
    "section": "üìä Training History",
    "text": "üìä Training History\nVisualize accuracy and loss across epochs for both training and validation sets.\n\n# Plot Accuracy and Loss\nacc = history.history['accuracy']\nval_acc = history.history['val_accuracy']\nloss = history.history['loss']\nval_loss = history.history['val_loss']\nepochs = range(1, len(acc) + 1)\n\nplt.figure(figsize=(12, 5))\nplt.subplot(1, 2, 1)\nplt.plot(epochs, acc, 'bo-', label='Training Accuracy')\nplt.plot(epochs, val_acc, 'ro-', label='Validation Accuracy')\nplt.title('Training vs. Validation Accuracy')\nplt.xlabel('Epochs')\nplt.ylabel('Accuracy')\nplt.legend()\n\nplt.subplot(1, 2, 2)\nplt.plot(epochs, loss, 'bo-', label='Training Loss')\nplt.plot(epochs, val_loss, 'ro-', label='Validation Loss')\nplt.title('Training vs. Validation Loss')\nplt.xlabel('Epochs')\nplt.ylabel('Loss')\nplt.legend()\n\nplt.tight_layout()\nplt.show()\n\n\n# Final Metrics\nfinal_epoch = len(acc) - 1\nprint(\"\\nFinal Epoch Metrics:\")\nprint(f\"Training Accuracy     : {acc[final_epoch]:.4f}\")\nprint(f\"Validation Accuracy   : {val_acc[final_epoch]:.4f}\")\nprint(f\"Training Loss         : {loss[final_epoch]:.4f}\")\nprint(f\"Validation Loss       : {val_loss[final_epoch]:.4f}\")"
  },
  {
    "objectID": "python-projects/Netflix2.html",
    "href": "python-projects/Netflix2.html",
    "title": "Project 1: Netflix Movie Trends in the 1990s",
    "section": "",
    "text": "Analyze Netflix movie data to uncover patterns in movie durations and genre trends during the 1990s."
  },
  {
    "objectID": "python-projects/Netflix2.html#objective",
    "href": "python-projects/Netflix2.html#objective",
    "title": "Project 1: Netflix Movie Trends in the 1990s",
    "section": "",
    "text": "Analyze Netflix movie data to uncover patterns in movie durations and genre trends during the 1990s."
  },
  {
    "objectID": "python-projects/Netflix2.html#tools-used",
    "href": "python-projects/Netflix2.html#tools-used",
    "title": "Project 1: Netflix Movie Trends in the 1990s",
    "section": "Tools Used",
    "text": "Tools Used\n\nPython Libraries: pandas, matplotlib\nTechniques: Data filtering, type conversion, value counts, histogram visualization"
  },
  {
    "objectID": "python-projects/Netflix2.html#key-questions",
    "href": "python-projects/Netflix2.html#key-questions",
    "title": "Project 1: Netflix Movie Trends in the 1990s",
    "section": "Key Questions",
    "text": "Key Questions\n\nWhat was the most common movie duration in the 1990s?\nHow many short action movies (&lt; 90 minutes) were released in that decade?"
  },
  {
    "objectID": "python-projects/Netflix2.html#summary-of-findings",
    "href": "python-projects/Netflix2.html#summary-of-findings",
    "title": "Project 1: Netflix Movie Trends in the 1990s",
    "section": "Summary of Findings",
    "text": "Summary of Findings\n\nThe most frequent duration was 94 minutes, showing a standard movie length for the 1990s.\nOnly 7 short action movies were released in that time period, indicating a preference for longer runtimes in that genre.\n\n\n# import Python librairies\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\n\n# load the netflix data set as pandas data frame\nNetflix = pd.read_csv(\"netflix_data.csv\")\n\n1.0 Data Preview and Inspection\n\n# to see first 5 columns of data frame\nNetflix.head()\n\n\n\n\n\n\n\n\nshow_id\ntype\ntitle\ndirector\ncast\ncountry\ndate_added\nrelease_year\nduration\ndescription\ngenre\n\n\n\n\n0\ns2\nMovie\n7:19\nJorge Michel Grau\nDemi√°n Bichir, H√©ctor Bonilla, Oscar Serrano, ...\nMexico\nDecember 23, 2016\n2016\n93\nAfter a devastating earthquake hits Mexico Cit...\nDramas\n\n\n1\ns3\nMovie\n23:59\nGilbert Chan\nTedd Chan, Stella Chung, Henley Hii, Lawrence ...\nSingapore\nDecember 20, 2018\n2011\n78\nWhen an army recruit is found dead, his fellow...\nHorror Movies\n\n\n2\ns4\nMovie\n9\nShane Acker\nElijah Wood, John C. Reilly, Jennifer Connelly...\nUnited States\nNovember 16, 2017\n2009\n80\nIn a postapocalyptic world, rag-doll robots hi...\nAction\n\n\n3\ns5\nMovie\n21\nRobert Luketic\nJim Sturgess, Kevin Spacey, Kate Bosworth, Aar...\nUnited States\nJanuary 1, 2020\n2008\n123\nA brilliant group of students become card-coun...\nDramas\n\n\n4\ns6\nTV Show\n46\nSerdar Akar\nErdal Be≈üik√ßioƒülu, Yasemin Allen, Melis Birkan...\nTurkey\nJuly 1, 2017\n2016\n1\nA genetics professor experiments with a treatm...\nInternational TV\n\n\n\n\n\n\n\n\n# to see last 5 columns of data frame\nNetflix.tail()\n\n\n\n\n\n\n\n\nshow_id\ntype\ntitle\ndirector\ncast\ncountry\ndate_added\nrelease_year\nduration\ndescription\ngenre\n\n\n\n\n4807\ns7779\nMovie\nZombieland\nRuben Fleischer\nJesse Eisenberg, Woody Harrelson, Emma Stone, ...\nUnited States\nNovember 1, 2019\n2009\n88\nLooking to survive in a world taken over by zo...\nComedies\n\n\n4808\ns7781\nMovie\nZoo\nShlok Sharma\nShashank Arora, Shweta Tripathi, Rahul Kumar, ...\nIndia\nJuly 1, 2018\n2018\n94\nA drug dealer starts having doubts about his t...\nDramas\n\n\n4809\ns7782\nMovie\nZoom\nPeter Hewitt\nTim Allen, Courteney Cox, Chevy Chase, Kate Ma...\nUnited States\nJanuary 11, 2020\n2006\n88\nDragged from civilian life, a former superhero...\nChildren\n\n\n4810\ns7783\nMovie\nZozo\nJosef Fares\nImad Creidi, Antoinette Turk, Elias Gergi, Car...\nSweden\nOctober 19, 2020\n2005\n99\nWhen Lebanon's Civil War deprives Zozo of his ...\nDramas\n\n\n4811\ns7784\nMovie\nZubaan\nMozez Singh\nVicky Kaushal, Sarah-Jane Dias, Raaghav Chanan...\nIndia\nMarch 2, 2019\n2015\n111\nA scrappy but poor boy worms his way into a ty...\nDramas\n\n\n\n\n\n\n\n\n# To see column: missing values in each column, column data type, and memory usage.\nNetflix.info()\n\n&lt;class 'pandas.core.frame.DataFrame'&gt;\nRangeIndex: 4812 entries, 0 to 4811\nData columns (total 11 columns):\n #   Column        Non-Null Count  Dtype \n---  ------        --------------  ----- \n 0   show_id       4812 non-null   object\n 1   type          4812 non-null   object\n 2   title         4812 non-null   object\n 3   director      4812 non-null   object\n 4   cast          4812 non-null   object\n 5   country       4812 non-null   object\n 6   date_added    4812 non-null   object\n 7   release_year  4812 non-null   int64 \n 8   duration      4812 non-null   int64 \n 9   description   4812 non-null   object\n 10  genre         4812 non-null   object\ndtypes: int64(2), object(9)\nmemory usage: 413.7+ KB\n\n\n\n# Generate summary statistics for all numeric columns in the Netflix DataFrame\nnetflix_df.describe()\n\nNameError: name 'netflix_df' is not defined\n\n\n\n# calculated the percentage of missing values per column \nmissing_pct = (Netflix.isnull().sum() / len(Netflix)) * 100\n\n\n# Display the percentage of missing values count for each column: filter only columns with missing values, but since the result is an empty Series\nmissing_pct = missing_pct[missing_pct &gt; 0].sort_values(ascending=False).round(2) \nprint(missing_pct)\n\nSeries([], dtype: float64)\n\n\nData types and conversion\n\n# Display the data type of each column in the Netflix DataFrame\nNetflix.dtypes\n\n\nshow_id                 object\ntype                    object\ntitle                   object\ndirector                object\ncast                    object\ncountry                 object\ndate_added      datetime64[ns]\nrelease_year             int64\nduration                 int64\ndescription             object\ngenre                   object\ndtype: object\n\n\nConvert data_added to date variable\n\n# Convert the \"date_added\" column to datetime format; invalid entries are set to NaT (Not a Time)\nNetflix[\"date_added\"] = pd.to_datetime(Netflix[\"date_added\"], errors=\"coerce\")\n\nCategorical EDA\n\n# Return a pandas series: Count the frequency of each unique category in the \"type\" column.\nNetflix[\"type\"].value_counts()\n\ntype\nMovie      4677\nTV Show     135\nName: count, dtype: int64\n\n\n\nsns.countplot(data= Netflix, x=\"type\")\nplt.show()\n\n\n\n\n\n# Return a pandas series: Count the proportion of each unique category in the \"type\" column.\nNetflix[\"type\"].value_counts(normalize=True)\n\ntype\nMovie      0.971945\nTV Show    0.028055\nName: proportion, dtype: float64\n\n\n\nNetflix[\"country\"].value_counts()\n\ncountry\nUnited States     1886\nIndia              864\nUnited Kingdom     311\nCanada             155\nFrance             133\n                  ... \nVenezuela            1\nZimbabwe             1\nNamibia              1\nSoviet Union         1\nCroatia              1\nName: count, Length: 72, dtype: int64\n\n\n\nNetflix[\"country\"].value_counts(normalize=True)\n\ncountry\nUnited States     0.391937\nIndia             0.179551\nUnited Kingdom    0.064630\nCanada            0.032211\nFrance            0.027639\n                    ...   \nVenezuela         0.000208\nZimbabwe          0.000208\nNamibia           0.000208\nSoviet Union      0.000208\nCroatia           0.000208\nName: proportion, Length: 72, dtype: float64\n\n\n\nprint(Netflix[\"country\"].nunique())\n\n72\n\n\n\nNetflix[\"genre\"].value_counts()\n\ngenre\nDramas                  1343\nComedies                1029\nAction                   696\nChildren                 421\nDocumentaries            352\nStand-Up                 283\nHorror Movies            239\nInternational Movies     100\nClassic Movies            69\nThrillers                 49\nInternational TV          39\nCrime TV                  30\nUncategorized             25\nIndependent Movies        20\nBritish TV                20\nAnime Features            18\nMusic                     14\nSci-Fi                    11\nCult Movies               11\nKids                      10\nAnime Series               9\nDocuseries                 7\nTV Shows                   4\nRomantic Movies            3\nTV Comedies                3\nTV Action                  2\nRomantic TV                1\nTV Horror                  1\nClassic                    1\nReality TV                 1\nLGBTQ Movies               1\nName: count, dtype: int64\n\n\n\nNetflix[\"genre\"].value_counts(normalize=True)\n\ngenre\nDramas                  0.279094\nComedies                0.213840\nAction                  0.144638\nChildren                0.087490\nDocumentaries           0.073150\nStand-Up                0.058811\nHorror Movies           0.049667\nInternational Movies    0.020781\nClassic Movies          0.014339\nThrillers               0.010183\nInternational TV        0.008105\nCrime TV                0.006234\nUncategorized           0.005195\nIndependent Movies      0.004156\nBritish TV              0.004156\nAnime Features          0.003741\nMusic                   0.002909\nSci-Fi                  0.002286\nCult Movies             0.002286\nKids                    0.002078\nAnime Series            0.001870\nDocuseries              0.001455\nTV Shows                0.000831\nRomantic Movies         0.000623\nTV Comedies             0.000623\nTV Action               0.000416\nRomantic TV             0.000208\nTV Horror               0.000208\nClassic                 0.000208\nReality TV              0.000208\nLGBTQ Movies            0.000208\nName: proportion, dtype: float64\n\n\n\nprint(Netflix[\"genre\"].nunique())\n\n31\n\n\nFilter Movies to the 1990s\n\n# Filter Movies to the 1990s\nmovies_df = Netflix[Netflix[\"type\"] == \"Movie\"].copy()\n\n\n# Filter movies released in the 1990s\nmovies_90s = movies_df[(movies_df[\"release_year\"] &gt;= 1990) & (movies_df[\"release_year\"] &lt; 2000)]\n\n\n# Visualize the distribution of movie durations\nplt.hist(movies_90s[\"duration\"])\nplt.title(\"Distribution of Movie Durations (1990s)\")\nplt.xlabel(\"Duration (minutes)\")\nplt.ylabel(\"Number of Movies\")\nplt.show()\n\n\n\n\n\nmin_date = movies_90s[\"release_year\"].min()\nmax_date = movies_90s[\"release_year\"].max()\nprint(min_date)\nprint(max_date)\n\n1990\n1999\n\n\nAnswer Question 1: Most Frequent Movie Duration\n\n# Find the most frequent duration\nduration = movies_90s[\"duration\"].mode()[0]  # mode returns a Series, so take the first\nprint(\"Most frequent duration:\", duration)\n\nMost frequent duration: 94\n\n\nInterpretation:\nA duration of 94 minutes suggests that typical 1990s films leaned toward a standard feature-length format ‚Äî long enough for storytelling but concise enough for wide audience appeal.\nThis insight aligns with industry patterns from that era, where movies often ranged between 90‚Äì120 minutes.\nAnswer Question 2: Count Short Action Movies &lt; 90 min\n\n# Filter Action movies from the 1990s\nshort_action = movies_90s[(movies_90s[\"genre\"] == \"Action\") & (movies_90s[\"duration\"] &lt; 90)]\n\n# Count how many Action movies had a duration under 90 minutes\nshort_action_count = (short_action[\"duration\"] &lt; 90).sum()\n\n#short_movie_count = short_action.shape[0]\nprint(\"Short Action Movies:\", short_movie_count)\n\nShort Action Movies: 7\n\n\nInterpretation:\nAction movies during the 1990s were generally longer than 90 minutes, likely due to their complex plots, action sequences, and production style.\nThe relatively small number (7 out of all action movies) implies that short-form action content was rare, possibly limited to niche markets or lower-budget productions."
  },
  {
    "objectID": "python-projects/Netflix2.html#insights",
    "href": "python-projects/Netflix2.html#insights",
    "title": "Project 1: Netflix Movie Trends in the 1990s",
    "section": "Insights",
    "text": "Insights\n\nA majority of 1990s Netflix movies are around 94 minutes, suggesting a consistent production format.\nAction movies during the same decade were rarely shorter than 90 minutes, hinting at genre-driven runtime requirements."
  },
  {
    "objectID": "python-projects/Netflix2.html#next-steps",
    "href": "python-projects/Netflix2.html#next-steps",
    "title": "Project 1: Netflix Movie Trends in the 1990s",
    "section": "Next Steps",
    "text": "Next Steps\n\nExtend the analysis to other genres or time periods (2000s, 2010s)\nAdd more complex filters (e.g., by country or rating)\nConsider clustering movies by duration + genre + country for pattern discovery (Project 2)"
  },
  {
    "objectID": "python-projects/Netflix2.html#portfolio-use",
    "href": "python-projects/Netflix2.html#portfolio-use",
    "title": "Project 1: Netflix Movie Trends in the 1990s",
    "section": "Portfolio Use",
    "text": "Portfolio Use\nThis project demonstrates ability to: - Clean and preprocess a real-world dataset - Apply basic statistics and visualization - Answer business-relevant questions using data"
  },
  {
    "objectID": "python-projects/Final_project_VIF_NeuralNetwork_Portfolio.html",
    "href": "python-projects/Final_project_VIF_NeuralNetwork_Portfolio.html",
    "title": "Water Pump Functionality Prediction - Portfolio Project",
    "section": "",
    "text": "This project explores the use of machine learning to predict the functionality status of water pumps in rural areas. The dataset includes features such as water source, pump type, distance to town, population served, and funding organization.\nGoal: Build a predictive model to determine whether a water pump is functional or non-functional.\n\n# Import Libraries\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport os\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import classification_report, confusion_matrix\nfrom statsmodels.stats.outliers_influence import variance_inflation_factor\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Dense, Dropout\nfrom tensorflow.keras.optimizers import Adam\nfrom tensorflow.keras.callbacks import EarlyStopping"
  },
  {
    "objectID": "python-projects/Final_project_VIF_NeuralNetwork_Portfolio.html#project-overview",
    "href": "python-projects/Final_project_VIF_NeuralNetwork_Portfolio.html#project-overview",
    "title": "Water Pump Functionality Prediction - Portfolio Project",
    "section": "",
    "text": "This project explores the use of machine learning to predict the functionality status of water pumps in rural areas. The dataset includes features such as water source, pump type, distance to town, population served, and funding organization.\nGoal: Build a predictive model to determine whether a water pump is functional or non-functional.\n\n# Import Libraries\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport os\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import classification_report, confusion_matrix\nfrom statsmodels.stats.outliers_influence import variance_inflation_factor\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Dense, Dropout\nfrom tensorflow.keras.optimizers import Adam\nfrom tensorflow.keras.callbacks import EarlyStopping"
  },
  {
    "objectID": "python-projects/Final_project_VIF_NeuralNetwork_Portfolio.html#set-and-verify-working-directory",
    "href": "python-projects/Final_project_VIF_NeuralNetwork_Portfolio.html#set-and-verify-working-directory",
    "title": "Water Pump Functionality Prediction - Portfolio Project",
    "section": "Set and Verify Working Directory",
    "text": "Set and Verify Working Directory\nBefore loading the dataset, we confirm the current working directory and change it to the location where the cleaned data file is stored.\n\n# Set and Verify Working Directory\n\n# PYthon library\nimport os\n\nprint(\"Current working directory:\", os.getcwd())\n\nos.chdir(r\"C:\\Users\\jgpet\\OneDrive\\Desktop\\Gradiate school\\2025\\DSCI 5240\\Final Project\")\nprint(\"New working directory:\", os.getcwd())\n\nCurrent working directory: C:\\Users\\jgpet\\DSCI5240\\Final Project\nNew working directory: C:\\Users\\jgpet\\OneDrive\\Desktop\\Gradiate school\\2025\\DSCI 5240\\Final Project"
  },
  {
    "objectID": "python-projects/Final_project_VIF_NeuralNetwork_Portfolio.html#load-dataset",
    "href": "python-projects/Final_project_VIF_NeuralNetwork_Portfolio.html#load-dataset",
    "title": "Water Pump Functionality Prediction - Portfolio Project",
    "section": "Load Dataset",
    "text": "Load Dataset\nSet the working directory and load the cleaned dataset into memory.\n\n# Load Dataset\nFinal_project = pd.read_csv(\"Final_project_clean.csv\", header=0)\npd.set_option(\"display.max_columns\", None)"
  },
  {
    "objectID": "python-projects/Final_project_VIF_NeuralNetwork_Portfolio.html#handle-outliers",
    "href": "python-projects/Final_project_VIF_NeuralNetwork_Portfolio.html#handle-outliers",
    "title": "Water Pump Functionality Prediction - Portfolio Project",
    "section": "Handle Outliers",
    "text": "Handle Outliers\nUse the IQR method to detect and cap outliers in numerical features: - Distance to Nearest Town - Population Served - Water Pump Age\n\n# Outlier Detection & Capping\nnum_cols = ['Distance to Nearest Town', 'Population Served', 'Water Pump Age']\n\nfor col in num_cols:\n    Q1 = Final_project[col].quantile(0.25)\n    Q3 = Final_project[col].quantile(0.75)\n    IQR = Q3 - Q1\n    lower_bound = Q1 - 1.5 * IQR\n    upper_bound = Q3 + 1.5 * IQR\n    Final_project[col] = Final_project[col].clip(lower=lower_bound, upper=upper_bound)\n\n# Clip distance values below 0 to 0\nFinal_project['Distance to Nearest Town'] = Final_project['Distance to Nearest Town'].clip(lower=0)"
  },
  {
    "objectID": "python-projects/Final_project_VIF_NeuralNetwork_Portfolio.html#encode-categorical-variables",
    "href": "python-projects/Final_project_VIF_NeuralNetwork_Portfolio.html#encode-categorical-variables",
    "title": "Water Pump Functionality Prediction - Portfolio Project",
    "section": "üî§ Encode Categorical Variables",
    "text": "üî§ Encode Categorical Variables\n\nBinary encoding for Water Quality, Payment Type, and Functioning Status\n\nOne-hot encoding for Water Source Type, Funder, Pump Type\n\n\n# Encode Categorical Variables\nbinary_map = {\n    'Water Quality': {'Clean': 0, 'Contaminated': 1},\n    'Payment Type': {'Free': 0, 'Pay per use': 1},\n    'Functioning Status': {'Not Functioning': 0, 'Functioning': 1}\n}\ndf_encoded = Final_project.replace(binary_map)\ncategorical_cols = ['Water Source Type', 'Funder', 'Pump Type']\ndf_encoded = pd.get_dummies(df_encoded, columns=categorical_cols, drop_first=True)\ndf_encoded = df_encoded.astype(int)\n\nC:\\Users\\jgpet\\AppData\\Local\\Temp\\ipykernel_27700\\130284717.py:7: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n  df_encoded = Final_project.replace(binary_map)"
  },
  {
    "objectID": "python-projects/Final_project_VIF_NeuralNetwork_Portfolio.html#variance-inflation-factor-vif",
    "href": "python-projects/Final_project_VIF_NeuralNetwork_Portfolio.html#variance-inflation-factor-vif",
    "title": "Water Pump Functionality Prediction - Portfolio Project",
    "section": "üßÆ Variance Inflation Factor (VIF)",
    "text": "üßÆ Variance Inflation Factor (VIF)\nDetect multicollinearity and remove features with VIF &gt; 10 to improve model interpretability.\n\n# Define X and y\ny = df_encoded['Functioning Status']\nX = df_encoded.drop(columns='Functioning Status')\n\n# VIF for Feature Selection\nX_vif = X.astype(float)\nvif_data = pd.DataFrame()\nvif_data['Feature'] = X_vif.columns\nvif_data['VIF'] = [variance_inflation_factor(X_vif.values, i) for i in range(X_vif.shape[1])]\n\n# Drop high VIF features\nhigh_vif_features = ['Installation Year', 'Population Served']\nX_reduced = X.drop(columns=high_vif_features)"
  },
  {
    "objectID": "python-projects/Final_project_VIF_NeuralNetwork_Portfolio.html#feature-scaling",
    "href": "python-projects/Final_project_VIF_NeuralNetwork_Portfolio.html#feature-scaling",
    "title": "Water Pump Functionality Prediction - Portfolio Project",
    "section": "üìè Feature Scaling",
    "text": "üìè Feature Scaling\nStandardize numerical features to ensure they contribute equally to the model.\n\n# Scaling\n\nscaler = StandardScaler()\nnumeric_cols = ['Distance to Nearest Town', 'Water Pump Age']\nX_scaled = X_reduced.copy()\nX_scaled[numeric_cols] = scaler.fit_transform(X_scaled[numeric_cols])"
  },
  {
    "objectID": "python-projects/Final_project_VIF_NeuralNetwork_Portfolio.html#neural-network-model-keras",
    "href": "python-projects/Final_project_VIF_NeuralNetwork_Portfolio.html#neural-network-model-keras",
    "title": "Water Pump Functionality Prediction - Portfolio Project",
    "section": "ü§ñ Neural Network Model (Keras)",
    "text": "ü§ñ Neural Network Model (Keras)\nTrain a neural network to classify water pumps as functioning or not.\n\n# Train-Test Split\nX_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.3, random_state=4)\n\n\n# Build Neural Network\nmodel = Sequential([\n    Dense(16, activation='relu', input_shape=(X_train.shape[1],)),\n    Dropout(0.3),\n    Dense(12, activation='relu'),\n    Dropout(0.3),\n    Dense(6, activation='relu'),\n    Dropout(0.3),\n    Dense(1, activation='sigmoid')\n])\n\nC:\\Users\\jgpet\\anaconda31\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n\n\n\nmodel.compile(optimizer=Adam(learning_rate=0.001), loss='binary_crossentropy', metrics=['accuracy'])\nearly_stop = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n\n# Train Model\nhistory = model.fit(\n    X_train, y_train,\n    validation_split=0.2,\n    epochs=50,\n    batch_size=32,\n    callbacks=[early_stop],\n    verbose=1\n)\n\nEpoch 1/50\n88/88 ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 5s 12ms/step - accuracy: 0.5993 - loss: 0.6793 - val_accuracy: 0.6529 - val_loss: 0.6523\nEpoch 2/50\n88/88 ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 0s 5ms/step - accuracy: 0.6135 - loss: 0.6658 - val_accuracy: 0.6529 - val_loss: 0.6388\nEpoch 3/50\n88/88 ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 0s 4ms/step - accuracy: 0.6295 - loss: 0.6504 - val_accuracy: 0.6657 - val_loss: 0.6242\nEpoch 4/50\n88/88 ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 1s 4ms/step - accuracy: 0.6377 - loss: 0.6417 - val_accuracy: 0.6657 - val_loss: 0.6134\nEpoch 5/50\n88/88 ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 0s 4ms/step - accuracy: 0.6579 - loss: 0.6326 - val_accuracy: 0.6886 - val_loss: 0.6032\nEpoch 6/50\n88/88 ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 0s 5ms/step - accuracy: 0.6732 - loss: 0.6182 - val_accuracy: 0.6957 - val_loss: 0.5947\nEpoch 7/50\n88/88 ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 0s 4ms/step - accuracy: 0.6771 - loss: 0.6103 - val_accuracy: 0.6986 - val_loss: 0.5933\nEpoch 8/50\n88/88 ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 1s 3ms/step - accuracy: 0.6683 - loss: 0.6196 - val_accuracy: 0.6871 - val_loss: 0.5915\nEpoch 9/50\n88/88 ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 0s 4ms/step - accuracy: 0.6586 - loss: 0.6161 - val_accuracy: 0.6929 - val_loss: 0.5880\nEpoch 10/50\n88/88 ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 0s 3ms/step - accuracy: 0.6893 - loss: 0.5879 - val_accuracy: 0.6971 - val_loss: 0.5845\nEpoch 11/50\n88/88 ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 0s 3ms/step - accuracy: 0.6834 - loss: 0.6039 - val_accuracy: 0.6971 - val_loss: 0.5832\nEpoch 12/50\n88/88 ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 0s 2ms/step - accuracy: 0.6925 - loss: 0.5975 - val_accuracy: 0.6971 - val_loss: 0.5854\nEpoch 13/50\n88/88 ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 0s 2ms/step - accuracy: 0.6901 - loss: 0.5994 - val_accuracy: 0.7000 - val_loss: 0.5823\nEpoch 14/50\n88/88 ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 0s 2ms/step - accuracy: 0.7082 - loss: 0.5852 - val_accuracy: 0.7014 - val_loss: 0.5810\nEpoch 15/50\n88/88 ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 0s 3ms/step - accuracy: 0.6927 - loss: 0.6031 - val_accuracy: 0.7014 - val_loss: 0.5791\nEpoch 16/50\n88/88 ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 0s 3ms/step - accuracy: 0.6861 - loss: 0.6062 - val_accuracy: 0.7029 - val_loss: 0.5805\nEpoch 17/50\n88/88 ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 0s 2ms/step - accuracy: 0.7111 - loss: 0.5736 - val_accuracy: 0.6971 - val_loss: 0.5785\nEpoch 18/50\n88/88 ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 0s 3ms/step - accuracy: 0.6947 - loss: 0.5939 - val_accuracy: 0.7014 - val_loss: 0.5812\nEpoch 19/50\n88/88 ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 0s 3ms/step - accuracy: 0.7112 - loss: 0.5755 - val_accuracy: 0.7057 - val_loss: 0.5781\nEpoch 20/50\n88/88 ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 0s 2ms/step - accuracy: 0.7095 - loss: 0.5892 - val_accuracy: 0.7043 - val_loss: 0.5781\nEpoch 21/50\n88/88 ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 0s 3ms/step - accuracy: 0.7064 - loss: 0.5863 - val_accuracy: 0.7000 - val_loss: 0.5772\nEpoch 22/50\n88/88 ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 0s 3ms/step - accuracy: 0.7113 - loss: 0.5780 - val_accuracy: 0.7029 - val_loss: 0.5793\nEpoch 23/50\n88/88 ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 0s 3ms/step - accuracy: 0.7144 - loss: 0.5758 - val_accuracy: 0.7057 - val_loss: 0.5759\nEpoch 24/50\n88/88 ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 0s 2ms/step - accuracy: 0.7124 - loss: 0.5747 - val_accuracy: 0.7029 - val_loss: 0.5732\nEpoch 25/50\n88/88 ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 0s 4ms/step - accuracy: 0.7094 - loss: 0.5882 - val_accuracy: 0.7043 - val_loss: 0.5739\nEpoch 26/50\n88/88 ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 0s 3ms/step - accuracy: 0.7233 - loss: 0.5753 - val_accuracy: 0.7043 - val_loss: 0.5737\nEpoch 27/50\n88/88 ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 1s 5ms/step - accuracy: 0.7068 - loss: 0.5758 - val_accuracy: 0.7043 - val_loss: 0.5743\nEpoch 28/50\n88/88 ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 0s 4ms/step - accuracy: 0.7174 - loss: 0.5662 - val_accuracy: 0.7086 - val_loss: 0.5745\nEpoch 29/50\n88/88 ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 0s 4ms/step - accuracy: 0.7290 - loss: 0.5575 - val_accuracy: 0.7071 - val_loss: 0.5745"
  },
  {
    "objectID": "python-projects/Final_project_VIF_NeuralNetwork_Portfolio.html#model-evaluation",
    "href": "python-projects/Final_project_VIF_NeuralNetwork_Portfolio.html#model-evaluation",
    "title": "Water Pump Functionality Prediction - Portfolio Project",
    "section": "üìà Model Evaluation",
    "text": "üìà Model Evaluation\nDisplay classification report and confusion matrix to evaluate performance.\n\n# Evaluate Model\ny_pred = (model.predict(X_test) &gt; 0.5).astype(\"int32\")\nprint(\"\\nClassification Report:\\n\", classification_report(y_test, y_pred))\nprint(\"\\nConfusion Matrix:\\n\", confusion_matrix(y_test, y_pred))\n\n47/47 ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 0s 2ms/step\n\nClassification Report:\n               precision    recall  f1-score   support\n\n           0       0.76      0.83      0.80       936\n           1       0.67      0.58      0.62       564\n\n    accuracy                           0.73      1500\n   macro avg       0.72      0.70      0.71      1500\nweighted avg       0.73      0.73      0.73      1500\n\n\nConfusion Matrix:\n [[776 160]\n [239 325]]"
  },
  {
    "objectID": "python-projects/Final_project_VIF_NeuralNetwork_Portfolio.html#training-history",
    "href": "python-projects/Final_project_VIF_NeuralNetwork_Portfolio.html#training-history",
    "title": "Water Pump Functionality Prediction - Portfolio Project",
    "section": "üìä Training History",
    "text": "üìä Training History\nVisualize accuracy and loss across epochs for both training and validation sets.\n\n# Plot Accuracy and Loss\nacc = history.history['accuracy']\nval_acc = history.history['val_accuracy']\nloss = history.history['loss']\nval_loss = history.history['val_loss']\nepochs = range(1, len(acc) + 1)\n\nplt.figure(figsize=(12, 5))\nplt.subplot(1, 2, 1)\nplt.plot(epochs, acc, 'bo-', label='Training Accuracy')\nplt.plot(epochs, val_acc, 'ro-', label='Validation Accuracy')\nplt.title('Training vs. Validation Accuracy')\nplt.xlabel('Epochs')\nplt.ylabel('Accuracy')\nplt.legend()\n\nplt.subplot(1, 2, 2)\nplt.plot(epochs, loss, 'bo-', label='Training Loss')\nplt.plot(epochs, val_loss, 'ro-', label='Validation Loss')\nplt.title('Training vs. Validation Loss')\nplt.xlabel('Epochs')\nplt.ylabel('Loss')\nplt.legend()\n\nplt.tight_layout()\nplt.show()\n\n\n\n\n\n# Final Metrics\nfinal_epoch = len(acc) - 1\nprint(\"\\nFinal Epoch Metrics:\")\nprint(f\"Training Accuracy     : {acc[final_epoch]:.4f}\")\nprint(f\"Validation Accuracy   : {val_acc[final_epoch]:.4f}\")\nprint(f\"Training Loss         : {loss[final_epoch]:.4f}\")\nprint(f\"Validation Loss       : {val_loss[final_epoch]:.4f}\")\n\n\nFinal Epoch Metrics:\nTraining Accuracy     : 0.7250\nValidation Accuracy   : 0.7071\nTraining Loss         : 0.5669\nValidation Loss       : 0.5745"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Turning Data into Insight ‚Äî One Project at a Time",
    "section": "",
    "text": "Hello and thank you for visiting! I‚Äôm James Peters, a passionate data professional with a strong foundation in analytics, business strategy, and process improvement.\nThis portfolio showcases a curated selection of my favorite projects in R, Python, Excel, and Six Sigma ‚Äî each solving real-world challenges through data-driven insight.\n\nWhether it‚Äôs building predictive models, streamlining business operations, or visualizing key performance metrics, I approach every problem with curiosity, creativity, and a drive for clarity and impact.\n\nüîç What You‚Äôll Find Here:\n\nüìä R Projects focused on statistical modeling and visualization\n\nüêç Python Projects for machine learning, automation, and APIs\n\nüìà Excel Dashboards for quick insights and business KPIs\n\n‚öôÔ∏è Six Sigma projects improving processes through Lean methodology\n\n\n\n‚ÄúI believe data isn‚Äôt just about numbers ‚Äî it‚Äôs about momentum, meaning, and making a difference.‚Äù\n\n\n\nüîó GitHub üîó LinkedIn"
  },
  {
    "objectID": "Featured projects/index.html",
    "href": "Featured projects/index.html",
    "title": "Featured Projects",
    "section": "",
    "text": "Featured Project #- Project 2"
  },
  {
    "objectID": "Featured projects/index.html#my-featured-projects.",
    "href": "Featured projects/index.html#my-featured-projects.",
    "title": "Featured Projects",
    "section": "",
    "text": "Featured Project #- Project 2"
  },
  {
    "objectID": "Excel-Projects/excel-projects2.html",
    "href": "Excel-Projects/excel-projects2.html",
    "title": "excel Projects",
    "section": "",
    "text": "About this site\n```"
  },
  {
    "objectID": "about Me.html",
    "href": "about Me.html",
    "title": "\nAbout Me\n",
    "section": "",
    "text": "Hi, I‚Äôm James Peters ‚Äî a U.S. military veteran turned data professional with a deep passion for transforming messy data into meaningful insights.\nI bring over 7 years of experience in business analysis, including hands-on work with SQL, SAS, and Oracle, as well as advanced training in Python, R, Power BI, and Six Sigma methodology. My career has spanned financial services, airline operations, and process improvement ‚Äî where I‚Äôve helped teams move from gut instinct to data-backed decisions."
  },
  {
    "objectID": "about Me.html#my-focus-areas",
    "href": "about Me.html#my-focus-areas",
    "title": "\nAbout Me\n",
    "section": "üîç My Focus Areas",
    "text": "üîç My Focus Areas\n\nüìä Analytics & Business Intelligence\nCrafting dashboards and reports that turn complex metrics into actionable stories.\nü§ñ Data Science & Machine Learning\nUsing models to uncover patterns, predict outcomes, and automate insight generation.\nüõ†Ô∏è Process Optimization\nLeveraging Lean Six Sigma to streamline operations and reduce inefficiencies.\nüåê Cloud & Data Engineering Foundations\nActively developing skills in Azure and modern data infrastructure."
  },
  {
    "objectID": "about Me.html#my-mission",
    "href": "about Me.html#my-mission",
    "title": "\nAbout Me\n",
    "section": "üéØ My Mission",
    "text": "üéØ My Mission\n\n‚ÄúUse data with integrity, clarity, and creativity ‚Äî to improve systems, empower people, and make a difference.‚Äù"
  },
  {
    "objectID": "about Me.html#quick-facts",
    "href": "about Me.html#quick-facts",
    "title": "\nAbout Me\n",
    "section": "üí° Quick Facts",
    "text": "üí° Quick Facts\n\nüéì Master‚Äôs in Advanced Data Analytics\n\nüéì Currently pursuing a second Master‚Äôs in Business Analytics\n\nüîß Building a portfolio across R, Python, Excel, and Six Sigma\n\nüß≠ Purpose-driven. Detail-oriented. Systems thinker."
  },
  {
    "objectID": "Excel-Projects/excel-projects.html",
    "href": "Excel-Projects/excel-projects.html",
    "title": "excel Projects",
    "section": "",
    "text": "About this site"
  },
  {
    "objectID": "Excel-Projects/index.html",
    "href": "Excel-Projects/index.html",
    "title": "Excel Projects",
    "section": "",
    "text": "Project 1\nProject 2"
  },
  {
    "objectID": "Excel-Projects/index.html#my-excel-projects.",
    "href": "Excel-Projects/index.html#my-excel-projects.",
    "title": "Excel Projects",
    "section": "",
    "text": "Project 1\nProject 2"
  },
  {
    "objectID": "Featured projects/Netflix2.html",
    "href": "Featured projects/Netflix2.html",
    "title": "Featured Project: Netflix Movie Trends in the 1990s",
    "section": "",
    "text": "The objective of this project is to perform an in-depth exploratory data analysis (EDA) of Netflix‚Äôs content catalog. We aim to:\n\nIdentify trends in movie and TV show releases by year and genre.\nAnalyze the distribution of content across countries.\nDetermine patterns in content ratings (e.g., TV-MA, PG, etc.).\nProvide insights that can support business strategy, such as regional content preferences and genre saturation.\n\nThis analysis was conducted using Python and libraries such as pandas, matplotlib, and seaborn, and is presented via interactive visuals in Power BI"
  },
  {
    "objectID": "Featured projects/Netflix2.html#portfolio-use",
    "href": "Featured projects/Netflix2.html#portfolio-use",
    "title": "Featured Project: Netflix Movie Trends in the 1990s",
    "section": "Portfolio Use",
    "text": "Portfolio Use\nThis project demonstrates ability to: - Clean and preprocess a real-world dataset - Apply basic statistics and visualization - Answer business-relevant questions using data"
  },
  {
    "objectID": "Netflix2.html",
    "href": "Netflix2.html",
    "title": "Project 1: Netflix Movie Trends in the 1990s",
    "section": "",
    "text": "Analyze Netflix movie data to uncover patterns in movie durations and genre trends during the 1990s."
  },
  {
    "objectID": "Netflix2.html#objective",
    "href": "Netflix2.html#objective",
    "title": "Project 1: Netflix Movie Trends in the 1990s",
    "section": "",
    "text": "Analyze Netflix movie data to uncover patterns in movie durations and genre trends during the 1990s."
  },
  {
    "objectID": "Netflix2.html#tools-used",
    "href": "Netflix2.html#tools-used",
    "title": "Project 1: Netflix Movie Trends in the 1990s",
    "section": "Tools Used",
    "text": "Tools Used\n\nPython Libraries: pandas, matplotlib\nTechniques: Data filtering, type conversion, value counts, histogram visualization"
  },
  {
    "objectID": "Netflix2.html#key-questions",
    "href": "Netflix2.html#key-questions",
    "title": "Project 1: Netflix Movie Trends in the 1990s",
    "section": "Key Questions",
    "text": "Key Questions\n\nWhat was the most common movie duration in the 1990s?\nHow many short action movies (&lt; 90 minutes) were released in that decade?"
  },
  {
    "objectID": "Netflix2.html#summary-of-findings",
    "href": "Netflix2.html#summary-of-findings",
    "title": "Project 1: Netflix Movie Trends in the 1990s",
    "section": "Summary of Findings",
    "text": "Summary of Findings\n\nThe most frequent duration was 94 minutes, showing a standard movie length for the 1990s.\nOnly 7 short action movies were released in that time period, indicating a preference for longer runtimes in that genre.\n\n\n# import Python librairies\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\n\n# load the netflix data set as pandas data frame\nNetflix = pd.read_csv(\"netflix_data.csv\")\n\n1.0 Data Preview and Inspection\n\n# to see first 5 columns of data frame\nNetflix.head()\n\n\n\n\n\n\n\n\nshow_id\ntype\ntitle\ndirector\ncast\ncountry\ndate_added\nrelease_year\nduration\ndescription\ngenre\n\n\n\n\n0\ns2\nMovie\n7:19\nJorge Michel Grau\nDemi√°n Bichir, H√©ctor Bonilla, Oscar Serrano, ...\nMexico\nDecember 23, 2016\n2016\n93\nAfter a devastating earthquake hits Mexico Cit...\nDramas\n\n\n1\ns3\nMovie\n23:59\nGilbert Chan\nTedd Chan, Stella Chung, Henley Hii, Lawrence ...\nSingapore\nDecember 20, 2018\n2011\n78\nWhen an army recruit is found dead, his fellow...\nHorror Movies\n\n\n2\ns4\nMovie\n9\nShane Acker\nElijah Wood, John C. Reilly, Jennifer Connelly...\nUnited States\nNovember 16, 2017\n2009\n80\nIn a postapocalyptic world, rag-doll robots hi...\nAction\n\n\n3\ns5\nMovie\n21\nRobert Luketic\nJim Sturgess, Kevin Spacey, Kate Bosworth, Aar...\nUnited States\nJanuary 1, 2020\n2008\n123\nA brilliant group of students become card-coun...\nDramas\n\n\n4\ns6\nTV Show\n46\nSerdar Akar\nErdal Be≈üik√ßioƒülu, Yasemin Allen, Melis Birkan...\nTurkey\nJuly 1, 2017\n2016\n1\nA genetics professor experiments with a treatm...\nInternational TV\n\n\n\n\n\n\n\n\n# to see last 5 columns of data frame\nNetflix.tail()\n\n\n\n\n\n\n\n\nshow_id\ntype\ntitle\ndirector\ncast\ncountry\ndate_added\nrelease_year\nduration\ndescription\ngenre\n\n\n\n\n4807\ns7779\nMovie\nZombieland\nRuben Fleischer\nJesse Eisenberg, Woody Harrelson, Emma Stone, ...\nUnited States\nNovember 1, 2019\n2009\n88\nLooking to survive in a world taken over by zo...\nComedies\n\n\n4808\ns7781\nMovie\nZoo\nShlok Sharma\nShashank Arora, Shweta Tripathi, Rahul Kumar, ...\nIndia\nJuly 1, 2018\n2018\n94\nA drug dealer starts having doubts about his t...\nDramas\n\n\n4809\ns7782\nMovie\nZoom\nPeter Hewitt\nTim Allen, Courteney Cox, Chevy Chase, Kate Ma...\nUnited States\nJanuary 11, 2020\n2006\n88\nDragged from civilian life, a former superhero...\nChildren\n\n\n4810\ns7783\nMovie\nZozo\nJosef Fares\nImad Creidi, Antoinette Turk, Elias Gergi, Car...\nSweden\nOctober 19, 2020\n2005\n99\nWhen Lebanon's Civil War deprives Zozo of his ...\nDramas\n\n\n4811\ns7784\nMovie\nZubaan\nMozez Singh\nVicky Kaushal, Sarah-Jane Dias, Raaghav Chanan...\nIndia\nMarch 2, 2019\n2015\n111\nA scrappy but poor boy worms his way into a ty...\nDramas\n\n\n\n\n\n\n\n\n# To see column: missing values in each column, column data type, and memory usage.\nNetflix.info()\n\n&lt;class 'pandas.core.frame.DataFrame'&gt;\nRangeIndex: 4812 entries, 0 to 4811\nData columns (total 11 columns):\n #   Column        Non-Null Count  Dtype \n---  ------        --------------  ----- \n 0   show_id       4812 non-null   object\n 1   type          4812 non-null   object\n 2   title         4812 non-null   object\n 3   director      4812 non-null   object\n 4   cast          4812 non-null   object\n 5   country       4812 non-null   object\n 6   date_added    4812 non-null   object\n 7   release_year  4812 non-null   int64 \n 8   duration      4812 non-null   int64 \n 9   description   4812 non-null   object\n 10  genre         4812 non-null   object\ndtypes: int64(2), object(9)\nmemory usage: 413.7+ KB\n\n\n\n# Generate summary statistics for all numeric columns in the Netflix DataFrame\nNetflix.describe()\n\n\n\n\n\n\n\n\nrelease_year\nduration\n\n\n\n\ncount\n4812.000000\n4812.000000\n\n\nmean\n2012.711554\n99.566708\n\n\nstd\n9.517978\n30.889305\n\n\nmin\n1942.000000\n1.000000\n\n\n25%\n2011.000000\n88.000000\n\n\n50%\n2016.000000\n99.000000\n\n\n75%\n2018.000000\n116.000000\n\n\nmax\n2021.000000\n253.000000\n\n\n\n\n\n\n\n\n# calculated the percentage of missing values per column \nmissing_pct = (Netflix.isnull().sum() / len(Netflix)) * 100\n\n\n# Display the percentage of missing values count for each column: filter only columns with missing values, but since the result is an empty Series\nmissing_pct = missing_pct[missing_pct &gt; 0].sort_values(ascending=False).round(2) \nprint(missing_pct)\n\nSeries([], dtype: float64)\n\n\nData types and conversion\n\n# Display the data type of each column in the Netflix DataFrame\nNetflix.dtypes\n\nshow_id         object\ntype            object\ntitle           object\ndirector        object\ncast            object\ncountry         object\ndate_added      object\nrelease_year     int64\nduration         int64\ndescription     object\ngenre           object\ndtype: object\n\n\nConvert data_added to date variable\n\n# Convert the \"date_added\" column to datetime format; invalid entries are set to NaT (Not a Time)\nNetflix[\"date_added\"] = pd.to_datetime(Netflix[\"date_added\"], errors=\"coerce\")\n\nCategorical EDA\n\n# Return a pandas series: Count the frequency of each unique category in the \"type\" column.\nNetflix[\"type\"].value_counts()\n\ntype\nMovie      4677\nTV Show     135\nName: count, dtype: int64\n\n\n\nsns.countplot(data= Netflix, x=\"type\")\nplt.show()\n\n\n\n\n\n# Return a pandas series: Count the proportion of each unique category in the \"type\" column.\nNetflix[\"type\"].value_counts(normalize=True)\n\ntype\nMovie      0.971945\nTV Show    0.028055\nName: proportion, dtype: float64\n\n\n\nNetflix[\"country\"].value_counts()\n\ncountry\nUnited States     1886\nIndia              864\nUnited Kingdom     311\nCanada             155\nFrance             133\n                  ... \nGuatemala            1\nJamaica              1\nParaguay             1\nSomalia              1\nCroatia              1\nName: count, Length: 72, dtype: int64\n\n\n\nNetflix[\"country\"].value_counts(normalize=True)\n\ncountry\nUnited States     0.391937\nIndia             0.179551\nUnited Kingdom    0.064630\nCanada            0.032211\nFrance            0.027639\n                    ...   \nGuatemala         0.000208\nJamaica           0.000208\nParaguay          0.000208\nSomalia           0.000208\nCroatia           0.000208\nName: proportion, Length: 72, dtype: float64\n\n\n\nprint(Netflix[\"country\"].nunique())\n\n72\n\n\n\nNetflix[\"genre\"].value_counts()\n\ngenre\nDramas                  1343\nComedies                1029\nAction                   696\nChildren                 421\nDocumentaries            352\nStand-Up                 283\nHorror Movies            239\nInternational Movies     100\nClassic Movies            69\nThrillers                 49\nInternational TV          39\nCrime TV                  30\nUncategorized             25\nBritish TV                20\nIndependent Movies        20\nAnime Features            18\nMusic                     14\nCult Movies               11\nSci-Fi                    11\nKids                      10\nAnime Series               9\nDocuseries                 7\nTV Shows                   4\nRomantic Movies            3\nTV Comedies                3\nTV Action                  2\nRomantic TV                1\nTV Horror                  1\nClassic                    1\nReality TV                 1\nLGBTQ Movies               1\nName: count, dtype: int64\n\n\n\nNetflix[\"genre\"].value_counts(normalize=True)\n\ngenre\nDramas                  0.279094\nComedies                0.213840\nAction                  0.144638\nChildren                0.087490\nDocumentaries           0.073150\nStand-Up                0.058811\nHorror Movies           0.049667\nInternational Movies    0.020781\nClassic Movies          0.014339\nThrillers               0.010183\nInternational TV        0.008105\nCrime TV                0.006234\nUncategorized           0.005195\nBritish TV              0.004156\nIndependent Movies      0.004156\nAnime Features          0.003741\nMusic                   0.002909\nCult Movies             0.002286\nSci-Fi                  0.002286\nKids                    0.002078\nAnime Series            0.001870\nDocuseries              0.001455\nTV Shows                0.000831\nRomantic Movies         0.000623\nTV Comedies             0.000623\nTV Action               0.000416\nRomantic TV             0.000208\nTV Horror               0.000208\nClassic                 0.000208\nReality TV              0.000208\nLGBTQ Movies            0.000208\nName: proportion, dtype: float64\n\n\n\nprint(Netflix[\"genre\"].nunique())\n\n31\n\n\nFilter Movies to the 1990s\n\n# Filter Movies to the 1990s\nmovies_df = Netflix[Netflix[\"type\"] == \"Movie\"].copy()\n\n\n# Filter movies released in the 1990s\nmovies_90s = movies_df[(movies_df[\"release_year\"] &gt;= 1990) & (movies_df[\"release_year\"] &lt; 2000)]\n\n\n# Visualize the distribution of movie durations\nplt.hist(movies_90s[\"duration\"])\nplt.title(\"Distribution of Movie Durations (1990s)\")\nplt.xlabel(\"Duration (minutes)\")\nplt.ylabel(\"Number of Movies\")\nplt.show()\n\n\n\n\n\nmin_date = movies_90s[\"release_year\"].min()\nmax_date = movies_90s[\"release_year\"].max()\nprint(min_date)\nprint(max_date)\n\n1990\n1999\n\n\nAnswer Question 1: Most Frequent Movie Duration\n\n# Find the most frequent duration\nduration = movies_90s[\"duration\"].mode()[0]  # mode returns a Series, so take the first\nprint(\"Most frequent duration:\", duration)\n\nMost frequent duration: 94\n\n\nInterpretation:\nA duration of 94 minutes suggests that typical 1990s films leaned toward a standard feature-length format ‚Äî long enough for storytelling but concise enough for wide audience appeal.\nThis insight aligns with industry patterns from that era, where movies often ranged between 90‚Äì120 minutes.\nAnswer Question 2: Count Short Action Movies &lt; 90 min\n\n# Filter Action movies from the 1990s\nshort_action = movies_90s[(movies_90s[\"genre\"] == \"Action\") & (movies_90s[\"duration\"] &lt; 90)]\n\n# Count how many Action movies had a duration under 90 minutes\nshort_action_count = (short_action[\"duration\"] &lt; 90).sum()\n\n#short_movie_count = short_action.shape[0]\nprint(\"Short Action Movies:\", short_action_count)\n\nShort Action Movies: 7\n\n\nInterpretation:\nAction movies during the 1990s were generally longer than 90 minutes, likely due to their complex plots, action sequences, and production style.\nThe relatively small number (7 out of all action movies) implies that short-form action content was rare, possibly limited to niche markets or lower-budget productions."
  },
  {
    "objectID": "Netflix2.html#insights",
    "href": "Netflix2.html#insights",
    "title": "Project 1: Netflix Movie Trends in the 1990s",
    "section": "Insights",
    "text": "Insights\n\nA majority of 1990s Netflix movies are around 94 minutes, suggesting a consistent production format.\nAction movies during the same decade were rarely shorter than 90 minutes, hinting at genre-driven runtime requirements."
  },
  {
    "objectID": "Netflix2.html#next-steps",
    "href": "Netflix2.html#next-steps",
    "title": "Project 1: Netflix Movie Trends in the 1990s",
    "section": "Next Steps",
    "text": "Next Steps\n\nExtend the analysis to other genres or time periods (2000s, 2010s)\nAdd more complex filters (e.g., by country or rating)\nConsider clustering movies by duration + genre + country for pattern discovery (Project 2)"
  },
  {
    "objectID": "Netflix2.html#portfolio-use",
    "href": "Netflix2.html#portfolio-use",
    "title": "Project 1: Netflix Movie Trends in the 1990s",
    "section": "Portfolio Use",
    "text": "Portfolio Use\nThis project demonstrates ability to: - Clean and preprocess a real-world dataset - Apply basic statistics and visualization - Answer business-relevant questions using data"
  },
  {
    "objectID": "python-projects/index.html",
    "href": "python-projects/index.html",
    "title": "Python Projects",
    "section": "",
    "text": "Project 1\nProject 2"
  },
  {
    "objectID": "python-projects/index.html#my-python-projects.",
    "href": "python-projects/index.html#my-python-projects.",
    "title": "Python Projects",
    "section": "",
    "text": "Project 1\nProject 2"
  },
  {
    "objectID": "python-projects/python-projects-2.html",
    "href": "python-projects/python-projects-2.html",
    "title": "Python Projects",
    "section": "",
    "text": "About this site\n\nimport pandas as pd\ndf = pd.DataFrame({\n  \"Name\": [\"Alice\", \"Bob\", \"Charlie\"],\n  \"Score\": [92, 88, 79]\n})\ndf\n\n\n\n\n\n\n\n\nName\nScore\n\n\n\n\n0\nAlice\n92\n\n\n1\nBob\n88\n\n\n2\nCharlie\n79"
  },
  {
    "objectID": "python-projects/python-projects-4.html",
    "href": "python-projects/python-projects-4.html",
    "title": "Numerical_eda",
    "section": "",
    "text": "import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n# This code imports the os as a module to interact with the operating system\nimport os\n\n# To display the current working directory to identity where Python is excecuting the scripts.\nprint(\"Current working directory:\", os.getcwd())\n\nCurrent working directory: C:\\Users\\jgpet\\OneDrive\\Desktop\\DATA ANALYST\\Data Analytic Portfolio\\Lets make Musicupdated\\python-projects\n# Change the working directory to the folder containing the file\nos.chdir(r\"C:\\Users\\jgpet\\OneDrive\\Desktop\\Gradiate school\\2025\\DSCI 5240\\Final Project\")\n\n# Verify the change\nprint(\"New working directory:\", os.getcwd())\n\nNew working directory: C:\\Users\\jgpet\\OneDrive\\Desktop\\Gradiate school\\2025\\DSCI 5240\\Final Project\n# Load data file inot python as a pandas data frame\n# Load data into Data frame using row 1 as the header\nFinal_project = pd.read_csv(\"DSCI 5240 Project Data.csv\", header=0)\n# Ensure all columns are displayed in a table format\npd.set_option(\"display.max_rows\", None)\npd.set_option(\"display.max_columns\", None)\npd.set_option(\"display.width\", 1000)\npd.set_option(\"display.colheader_justify\", \"center\")\n\nFinal_project.head()\n\n\n\n\n\n\n\n\nWater Pump ID\nWater Source Type\nWater Quality\nDistance to Nearest Town\nPopulation Served\nInstallation Year\nFunder\nPayment Type\nWater Pump Age\nPump Type\nGPS Coordinates\nFunctioning Status\n\n\n\n\n0\nWP001\nWell\nClean\n44.0\n13000.0\n2006.0\nWorld Bank\nFree\n18.0\nMotorized Pump\n(-20.599463060030295, 26.696000047794744)\nFunctioning\n\n\n1\nWP002\nLake\nClean\n13.0\n13000.0\n1990.0\nRed Cross\nFree\n34.0\nHand Pump\n(-20.69129769992364, 23.313405231404484)\nNot Functioning\n\n\n2\nWP003\nLake\nClean\n27.0\n12000.0\n1997.0\nOxfam\nPay per use\n27.0\nHand Pump\n(-19.830951420391948, 26.650358442338003)\nNot Functioning\n\n\n3\nWP004\nWell\nClean\n14.0\n9000.0\n1992.0\nOxfam\nPay per use\n32.0\nNaN\n(-22.335866062765565, 22.83485684389231)\nFunctioning\n\n\n4\nWP005\nLake\nClean\n41.0\n16000.0\n2006.0\nNaN\nPay per use\n18.0\nHand Pump\n(-21.099305692773278, 24.799143614430015)\nFunctioning\nFinal_project.info()\n\n&lt;class 'pandas.core.frame.DataFrame'&gt;\nRangeIndex: 5000 entries, 0 to 4999\nData columns (total 12 columns):\n #   Column                    Non-Null Count  Dtype  \n---  ------                    --------------  -----  \n 0   Water Pump ID             4750 non-null   object \n 1   Water Source Type         4750 non-null   object \n 2   Water Quality             4750 non-null   object \n 3   Distance to Nearest Town  4750 non-null   float64\n 4   Population Served         4750 non-null   float64\n 5   Installation Year         4750 non-null   float64\n 6   Funder                    4750 non-null   object \n 7   Payment Type              4750 non-null   object \n 8   Water Pump Age            4750 non-null   float64\n 9   Pump Type                 4750 non-null   object \n 10  GPS Coordinates           4750 non-null   object \n 11  Functioning Status        4750 non-null   object \ndtypes: float64(4), object(8)\nmemory usage: 468.9+ KB\nFinal_project.value_counts(\"Water Source Type\")\n\nWater Source Type\nLake        2377\nWell        1641\nRiver        578\nBorehole     154\nName: count, dtype: int64\nWater Source has 4 categories\nFinal_project.value_counts(\"Water Quality\")\n\nWater Quality\nClean           4232\nContaminated     518\nName: count, dtype: int64\nWater Source has 3 categories\nFinal_project.value_counts(\"Funder\")\n\nFunder\nRed Cross     1719\nOxfam         1417\nUSAID          705\nUNICEF         534\nWorld Bank     375\nName: count, dtype: int64\nWater Source has 6 categories\nFinal_project.value_counts(\"Payment Type\")\n\nPayment Type\nPay per use    3567\nFree           1183\nName: count, dtype: int64\nWater Source has 3 categories\nFinal_project.value_counts(\"Pump Type\")\n\nPump Type\nHand Pump         2470\nMotorized Pump    1832\nSolar Pump         448\nName: count, dtype: int64\nWater Source has 4 categories\nFinal_project.value_counts(\"Functioning Status\")\n\nFunctioning Status\nNot Functioning    2793\nFunctioning        1957\nName: count, dtype: int64\nWater Source has 3 categories\n# For numerical columns\n\nFinal_project.describe()\n\n\n\n\n\n\n\n\nDistance to Nearest Town\nPopulation Served\nInstallation Year\nWater Pump Age\n\n\n\n\ncount\n4750.000000\n4750.000000\n4750.000000\n4750.000000\n\n\nmean\n33.605684\n13020.210526\n2005.122947\n18.921895\n\n\nstd\n14.203737\n2974.803284\n8.893727\n8.881974\n\n\nmin\n-3.000000\n2000.000000\n1990.000000\n4.000000\n\n\n25%\n21.000000\n11000.000000\n1997.000000\n11.000000\n\n\n50%\n35.000000\n13000.000000\n2005.000000\n19.000000\n\n\n75%\n44.000000\n15000.000000\n2013.000000\n27.000000\n\n\nmax\n76.000000\n22000.000000\n2020.000000\n34.000000\n# Display missing values count for each column\nFinal_project.isnull().sum()\n\nWater Pump ID               250\nWater Source Type           250\nWater Quality               250\nDistance to Nearest Town    250\nPopulation Served           250\nInstallation Year           250\nFunder                      250\nPayment Type                250\nWater Pump Age              250\nPump Type                   250\nGPS Coordinates             250\nFunctioning Status          250\ndtype: int64\nA. Handle missing values\n# Fill categorical columns with the mode\ncategorical_columns = ['Water Source Type', 'Water Quality', 'Funder', 'Payment Type', 'Pump Type', 'Functioning Status']\n\nfor column in categorical_columns:\n    Final_project[column] = Final_project[column].fillna(Final_project[column].mode()[0])\n\n# Fill numerical columns with the median\nnumerical_columns = ['Distance to Nearest Town', 'Population Served', 'Installation Year', 'Water Pump Age']\n\nfor column in numerical_columns:\n    Final_project[column] = Final_project[column].fillna(Final_project[column].median())\n# to drop columns Water Pump ID and GPS Coordinates: Do they add value to the dataset?\nFinal_project_clean = Final_project.drop(columns=['Water Pump ID', 'GPS Coordinates'])\nFinal_project_clean.info()\n\n&lt;class 'pandas.core.frame.DataFrame'&gt;\nRangeIndex: 5000 entries, 0 to 4999\nData columns (total 10 columns):\n #   Column                    Non-Null Count  Dtype  \n---  ------                    --------------  -----  \n 0   Water Source Type         5000 non-null   object \n 1   Water Quality             5000 non-null   object \n 2   Distance to Nearest Town  5000 non-null   float64\n 3   Population Served         5000 non-null   float64\n 4   Installation Year         5000 non-null   float64\n 5   Funder                    5000 non-null   object \n 6   Payment Type              5000 non-null   object \n 7   Water Pump Age            5000 non-null   float64\n 8   Pump Type                 5000 non-null   object \n 9   Functioning Status        5000 non-null   object \ndtypes: float64(4), object(6)\nmemory usage: 390.8+ KB\nData types 1. Convert to string: Water Source Type, Water Quality, Funder, Payment Type, Pump Type, Functioning Status 2. Convert to Integer Installation Year, Water Pump Age, Distance to Nearest Town, Population Served?\n# Convert data types to strings\nFinal_project_clean['Water Source Type'] = Final_project_clean['Water Source Type'].astype('category')\nFinal_project_clean['Water Quality'] = Final_project_clean['Water Quality'].astype('category')\nFinal_project_clean['Funder'] = Final_project_clean['Funder'].astype('category')\nFinal_project_clean['Payment Type'] = Final_project_clean['Payment Type'].astype('category')\nFinal_project_clean['Pump Type'] = Final_project_clean['Pump Type'].astype('category')\nFinal_project_clean['Functioning Status'] = Final_project_clean['Functioning Status'].astype('category')\n# Convert data types to Integer: Installation Year, Water Pump Age, Distance to Nearest Town, Population Served\nFinal_project_clean['Installation Year'] = Final_project_clean['Installation Year'].astype('int')\nFinal_project_clean['Water Pump Age'] = Final_project_clean['Water Pump Age'].astype('int')\nFinal_project_clean['Distance to Nearest Town'] = Final_project_clean['Distance to Nearest Town'].astype('int')\nFinal_project_clean['Population Served'] = Final_project_clean['Population Served'].astype('int')\nFinal_project_clean.info()\n\n&lt;class 'pandas.core.frame.DataFrame'&gt;\nRangeIndex: 5000 entries, 0 to 4999\nData columns (total 10 columns):\n #   Column                    Non-Null Count  Dtype   \n---  ------                    --------------  -----   \n 0   Water Source Type         5000 non-null   category\n 1   Water Quality             5000 non-null   category\n 2   Distance to Nearest Town  5000 non-null   int64   \n 3   Population Served         5000 non-null   int64   \n 4   Installation Year         5000 non-null   int64   \n 5   Funder                    5000 non-null   category\n 6   Payment Type              5000 non-null   category\n 7   Water Pump Age            5000 non-null   int64   \n 8   Pump Type                 5000 non-null   category\n 9   Functioning Status        5000 non-null   category\ndtypes: category(6), int64(4)\nmemory usage: 186.6 KB\nFinal_project_clean.head()\n\n\n\n\n\n\n\n\nWater Source Type\nWater Quality\nDistance to Nearest Town\nPopulation Served\nInstallation Year\nFunder\nPayment Type\nWater Pump Age\nPump Type\nFunctioning Status\n\n\n\n\n0\nWell\nClean\n44\n13000\n2006\nWorld Bank\nFree\n18\nMotorized Pump\nFunctioning\n\n\n1\nLake\nClean\n13\n13000\n1990\nRed Cross\nFree\n34\nHand Pump\nNot Functioning\n\n\n2\nLake\nClean\n27\n12000\n1997\nOxfam\nPay per use\n27\nHand Pump\nNot Functioning\n\n\n3\nWell\nClean\n14\n9000\n1992\nOxfam\nPay per use\n32\nHand Pump\nFunctioning\n\n\n4\nLake\nClean\n41\n16000\n2006\nRed Cross\nPay per use\n18\nHand Pump\nFunctioning\nCategorical Values\nFinal_project_clean.value_counts(\"Water Source Type\")\n\nWater Source Type\nLake        2627\nWell        1641\nRiver        578\nBorehole     154\nName: count, dtype: int64\nFinal_project_clean.value_counts(\"Water Quality\")\n\nWater Quality\nClean           4482\nContaminated     518\nName: count, dtype: int64\nFinal_project_clean.value_counts(\"Funder\")\n\nFunder\nRed Cross     1969\nOxfam         1417\nUSAID          705\nUNICEF         534\nWorld Bank     375\nName: count, dtype: int64\nFinal_project_clean.value_counts(\"Payment Type\")\n\nPayment Type\nPay per use    3817\nFree           1183\nName: count, dtype: int64\nFinal_project_clean.value_counts(\"Pump Type\")\n\nPump Type\nHand Pump         2720\nMotorized Pump    1832\nSolar Pump         448\nName: count, dtype: int64\nFinal_project_clean.value_counts(\"Functioning Status\")\n\nFunctioning Status\nNot Functioning    3043\nFunctioning        1957\nName: count, dtype: int64\n# For numerical columns\n\n\nFinal_project_clean.describe()\n\n\n\n\n\n\n\n\nDistance to Nearest Town\nPopulation Served\nInstallation Year\nWater Pump Age\n\n\n\n\ncount\n5000.000000\n5000.000000\n5000.000000\n5000.000000\n\n\nmean\n33.675400\n13019.200000\n2005.116800\n18.925800\n\n\nstd\n13.847353\n2899.467665\n8.668529\n8.657048\n\n\nmin\n-3.000000\n2000.000000\n1990.000000\n4.000000\n\n\n25%\n22.000000\n11000.000000\n1998.000000\n12.000000\n\n\n50%\n35.000000\n13000.000000\n2005.000000\n19.000000\n\n\n75%\n44.000000\n15000.000000\n2012.000000\n26.000000\n\n\nmax\n76.000000\n22000.000000\n2020.000000\n34.000000"
  },
  {
    "objectID": "python-projects/python-projects-4.html#skewness-analysis-mean-vs.-median-are-the-vaiables-skewed",
    "href": "python-projects/python-projects-4.html#skewness-analysis-mean-vs.-median-are-the-vaiables-skewed",
    "title": "Numerical_eda",
    "section": "Skewness Analysis: Mean vs.¬†Median: Are the vaiables skewed",
    "text": "Skewness Analysis: Mean vs.¬†Median: Are the vaiables skewed\n\nPopulation Served: Mean = 13019.2, Median = 13000\nThis suggests that the distribution is approximately symmetric.\nDistance to Nearest Town: Mean = 33.7, Median = 35\nThis indicates a slight left skew, potentially due to the invalid -3 value, which will be addressed during data cleaning.\nInstallation Year: Mean = 2005.1, Median = 2005\nThis distribution is approximately symmetric.\nWater Pump Age: Mean = 18.9, Median = 19\nThis distribution is approximately symmetric.\n\n\nSummary\nThe skewness analysis helps us identify whether each numerical variable has a balanced distribution or is influenced by outliers or natural skewness (e.g., older pumps might be rare, shifting the age distribution). This is important when choosing modeling techniques later.\nStandard Deviation What Does Standard Deviation Tell You?\n\nLow Standard Deviation: Data points are close to the mean (low spread).\nHigh Standard Deviation: Data points are widely spread out from the mean.\nComparing the standard deviation to the mean gives a sense of relative spread."
  },
  {
    "objectID": "python-projects/python-projects-4.html#analysis-of-spread-standard-deviation",
    "href": "python-projects/python-projects-4.html#analysis-of-spread-standard-deviation",
    "title": "Numerical_eda",
    "section": "Analysis of Spread: Standard Deviation",
    "text": "Analysis of Spread: Standard Deviation\n\nDistance to Nearest Town\n\nMean: 33.68 km\nStandard Deviation: 13.85 km\nInterpretation: There is moderate spread ‚Äî some pumps are very close to towns, while others are quite far away.\nThis wide spread may affect accessibility and maintenance.\n\n\n\nPopulation Served\n\nMean: 13019.2 people\nStandard Deviation: 2899.47 people\nInterpretation: There is a large spread in population served, indicating that some water points serve much larger communities\nthan others. This variance could impact pump wear and tear, water quality, and functionality.\n\n\n\nInstallation Year\n\nMean: 2005.12\nStandard Deviation: 8.67 years\nInterpretation: This is a relatively low spread, meaning most pumps were installed within a similar timeframe. This could indicate\nconsistent development efforts over time.\n\n\n\nWater Pump Age\n\nMean: 18.93 years\nStandard Deviation: 8.66 years\nInterpretation: Pump age shows moderate spread, with some pumps significantly older than others. Older pumps may be more prone\nto breakdowns, which could explain patterns seen in the Functioning Status if any.\n\n\nfor col in numerical_columns:\n    plt.figure(figsize=(8, 4))\n    sns.histplot(Final_project_clean[col], kde=True, bins=20)\n    plt.title(f'Distribution of {col}')\n    plt.show()"
  },
  {
    "objectID": "python-projects/python-projects-4.html#distribution-analysis-of-numerical-variables",
    "href": "python-projects/python-projects-4.html#distribution-analysis-of-numerical-variables",
    "title": "Numerical_eda",
    "section": "Distribution Analysis of Numerical Variables",
    "text": "Distribution Analysis of Numerical Variables\nTo better understand the spread and shape of the numerical variables in the dataset, histograms with density curves (KDE) were generated for:\n\nDistance to Nearest Town\nPopulation Served\nInstallation Year\nWater Pump Age\n\n\nObservations\n\nDistance to Nearest Town:\n\nThe distribution appears roughly bimodal, indicating two distinct groups ‚Äî pumps either located very close to towns, or much farther away.\nThe presence of a negative distance (anomalous value) was also detected and will require data cleaning.\n\nPopulation Served:\n\nThe distribution is slightly right-skewed, meaning a small number of pumps serve very large populations compared to the majority.\nThis skewness could indicate a few outliers ‚Äî large water systems serving exceptionally large communities.\n\nInstallation Year:\n\nThe data is centered around the 2000s, showing a peak in installations during that period.\nThe distribution confirms that most pumps were installed between 1995 and 2015, aligning with global infrastructure development initiatives.\n\nWater Pump Age:\n\nThe age distribution is fairly even, but slightly skewed toward older pumps.\nThis suggests that some pumps have been operational for much longer than others, potentially impacting their functionality.\n\n\n\n\nConclusion\nThese distributions provide valuable insight into the data‚Äôs characteristics, potential outliers, and patterns that could influence later analysis, such as clustering or modeling pump functionality.\n\n# To detect outliers\nplt.figure(figsize=(12, 8))\nfor i, col in enumerate(numerical_columns, 1):\n    plt.subplot(2, 2, i)\n    sns.boxplot(x=Final_project_clean[col])\n    plt.title(f'Boxplot of {col}')\nplt.tight_layout()\nplt.show()"
  },
  {
    "objectID": "python-projects/python-projects-4.html#outlier-detection-using-boxplots",
    "href": "python-projects/python-projects-4.html#outlier-detection-using-boxplots",
    "title": "Numerical_eda",
    "section": "Outlier Detection Using Boxplots",
    "text": "Outlier Detection Using Boxplots\nBoxplots were generated for the numerical variables to identify potential outliers and analyze the spread of the data.\n\nObservations:\n\nDistance to Nearest Town:\n\nA negative value (-3) was detected, which is an invalid distance and will require data cleaning.\nThere are a few high-distance values that might be legitimate but should be investigated.\n\nPopulation Served:\n\nSome extreme values appear on the higher end, indicating that a few pumps serve significantly larger populations.\nThis could be due to large-scale water distribution systems, but further investigation is needed to determine if these are valid or data entry errors.\n\nInstallation Year:\n\nNo significant outliers detected. The values fall within a reasonable range (1990‚Äì2020), aligning with expected infrastructure development trends.\n\nWater Pump Age:\n\nSome older pumps seem to be outliers, but given that pumps can remain operational for long periods, these might be valid.\nFurther analysis could explore whether older pumps have a higher likelihood of not functioning.\n\n\n\n\nConclusion:\nIdentifying outliers is crucial for: 1. Data Cleaning ‚Äì Removing or correcting erroneous values (e.g., negative distances). 2. Feature Engineering ‚Äì Handling extreme values appropriately (e.g., winsorization or transformations). 3. Modeling Impact ‚Äì Deciding whether to retain or remove extreme values to improve analysis and predictions.\nOutliers will be further examined before proceeding with clustering and predictive analysis.\nCorrelation Between Numerical Variables\n\nplt.figure(figsize=(8,6))\nsns.heatmap(Final_project_clean[numerical_columns].corr(), annot=True, cmap=\"coolwarm\", fmt=\".2f\")\nplt.title('Correlation Matrix of Numerical Variables')\nplt.show()"
  },
  {
    "objectID": "python-projects/python-projects-4.html#correlation-analysis-of-numerical-variables",
    "href": "python-projects/python-projects-4.html#correlation-analysis-of-numerical-variables",
    "title": "Numerical_eda",
    "section": "Correlation Analysis of Numerical Variables",
    "text": "Correlation Analysis of Numerical Variables\nA correlation matrix was generated to examine the relationships between numerical variables. The heatmap visualizes the strength and direction of these correlations:\n\nKey Observations:\n\nWater Pump Age vs.¬†Installation Year: Strong negative correlation\n\nOlder pumps correspond to earlier installation years, which is expected.\nThis confirms that Water Pump Age is effectively derived from Installation Year.\n\nPopulation Served vs.¬†Distance to Nearest Town: Weak correlation\n\nNo strong relationship observed, indicating that pumps serving large populations are not necessarily located farther or closer to towns.\n\nOther Variables: Low correlation values\n\nMost numerical features in the dataset appear to be weakly correlated, meaning each provides distinct information.\n\n\n\n\nConclusion:\n\nThe negative correlation between Installation Year and Water Pump Age suggests multicollinearity, which might need to be addressed in predictive modeling.\nNo highly correlated features were found among Distance to Nearest Town, Population Served, and Functioning Status, indicating that these variables can contribute independently to further analysis (such as clustering or predictive modeling).\n\nIf you see correlation values:\nClose to +1 or -1 ‚Üí Strong relationship Between -0.3 and 0.3 ‚Üí Weak or no relationship Between 0.3 and 0.7 ‚Üí Moderate relationship\nTrends over time for installation Year\n\nsns.scatterplot(data=Final_project_clean, x='Installation Year', y='Population Served', hue='Functioning Status')\nplt.title('Population Served Over Time')\nplt.show()"
  },
  {
    "objectID": "python-projects/python-projects-4.html#population-served-over-time-by-functioning-status",
    "href": "python-projects/python-projects-4.html#population-served-over-time-by-functioning-status",
    "title": "Numerical_eda",
    "section": "Population Served Over Time by Functioning Status",
    "text": "Population Served Over Time by Functioning Status\nA scatterplot was generated to examine the relationship between Installation Year and Population Served, with the data points color-coded by the pump‚Äôs Functioning Status.\n\nKey Observations:\n\nThere is no clear trend indicating that newer installations consistently serve larger populations.\nBoth functioning and non-functioning pumps are distributed across all installation years and population sizes.\nHowever, older installations (pre-2000) show a slightly higher proportion of non-functioning pumps, indicating that age of the pump could be contributing to functionality issues.\nThe population served ranges widely across all installation years, with some pumps serving very large populations regardless of installation date.\n\n\n\nConclusion:\nThis plot helps highlight that functioning status may be weakly related to installation year ‚Äî older pumps appear slightly more prone to failure. However, population size alone does not appear to be a strong driver of functionality issues. This insight can guide further exploration, such as analyzing pump type, water source, or payment type in relation to functioning status.\nCheck Relationships to Functioning Status\n\nfor col in numerical_columns:\n    plt.figure(figsize=(8, 4))\n    sns.boxplot(data=Final_project_clean, x='Functioning Status', y=col)\n    plt.title(f'{col} vs Functioning Status')\n    plt.show()"
  },
  {
    "objectID": "python-projects/python-projects-4.html#numerical-variables-vs.-functioning-status",
    "href": "python-projects/python-projects-4.html#numerical-variables-vs.-functioning-status",
    "title": "Numerical_eda",
    "section": "Numerical Variables vs.¬†Functioning Status",
    "text": "Numerical Variables vs.¬†Functioning Status\nBoxplots were created to explore the relationship between each numerical variable and the functioning status of the water pumps. This helps identify whether certain numerical characteristics (e.g., age, population served, distance to town) differ between functioning and non-functioning pumps.\n\nKey Observations\n\nDistance to Nearest Town vs.¬†Functioning Status:\n\nFunctioning and non-functioning pumps have fairly similar distance distributions.\nThis suggests that distance to the nearest town may not have a strong influence on functionality.\n\nPopulation Served vs.¬†Functioning Status:\n\nNon-functioning pumps show a slightly wider spread in population served, indicating that pumps serving larger populations could face more stress or maintenance challenges.\nHowever, the median population served is very similar between the two groups, meaning this is not a strong driver on its own.\n\nInstallation Year vs.¬†Functioning Status:\n\nNon-functioning pumps tend to have slightly earlier installation years, aligning with the hypothesis that older pumps are more likely to fail.\nHowever, non-functioning pumps exist across all installation years, meaning age alone does not fully explain pump failure.\n\nWater Pump Age vs.¬†Functioning Status:\n\nNon-functioning pumps are generally older, with a higher median age compared to functioning pumps.\nThis supports the idea that older pumps are at greater risk of failure, likely due to wear and tear over time.\n\n\n\n\nConclusion\n\nWater Pump Age appears to have the strongest relationship with functionality, reinforcing the importance of preventative maintenance and timely replacements.\nOther numerical variables like Distance to Nearest Town and Population Served show weaker or inconsistent relationships with functioning status, suggesting that non-numeric factors (like pump type, water source type, or funder practices) may play a larger role in functionality.\n\n\nFinal_project_clean.to_csv('Final_project_clean.csv', index=False)\n\n\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nsns.histplot(data=Final_project_clean, x=\"Distance to Nearest Town\", binwidth=10)\n\n\nnumerical_columns = ['Distance to Nearest Town', 'Population Served', 'Installation Year', 'Water Pump Age']\n\n\n\n\n\nsns.histplot(data=Final_project_clean, x=\"Population Served\", binwidth=200)\n\n&lt;Axes: xlabel='Population Served', ylabel='Count'&gt;\n\n\n\n\n\n\nsns.histplot(data=Final_project_clean, x=\"Installation Year\", binwidth=1)\n\n&lt;Axes: xlabel='Installation Year', ylabel='Count'&gt;\n\n\n\n\n\n\nsns.histplot(data=Final_project_clean, x=\"Water Pump Age\", binwidth=1)\n\n&lt;Axes: xlabel='Water Pump Age', ylabel='Count'&gt;\n\n\n\n\n\n\nsns.boxplot(data=Final_project_clean, x=\"Distance to Nearest Town\")\n\n&lt;Axes: xlabel='Distance to Nearest Town'&gt;\n\n\n\n\n\n\nsns.boxplot(data=Final_project_clean, x=\"Population Served\")\n\n&lt;Axes: xlabel='Population Served'&gt;\n\n\n\n\n\n\nsns.boxplot(data=Final_project_clean, x=\"Installation Year\")\n\n&lt;Axes: xlabel='Installation Year'&gt;\n\n\n\n\n\n\nsns.boxplot(data=Final_project_clean, x=\"Water Pump Age\")\n\n&lt;Axes: xlabel='Water Pump Age'&gt;"
  },
  {
    "objectID": "R-projects/index.html",
    "href": "R-projects/index.html",
    "title": "R Projects",
    "section": "",
    "text": "Project 1\nProject 2 ```"
  },
  {
    "objectID": "R-projects/index.html#my-r-projects.",
    "href": "R-projects/index.html#my-r-projects.",
    "title": "R Projects",
    "section": "",
    "text": "Project 1\nProject 2 ```"
  },
  {
    "objectID": "R-projects/r-projects.html",
    "href": "R-projects/r-projects.html",
    "title": "R Projects",
    "section": "",
    "text": "About this site\n\nsummary(mtcars)\n\n      mpg             cyl             disp             hp       \n Min.   :10.40   Min.   :4.000   Min.   : 71.1   Min.   : 52.0  \n 1st Qu.:15.43   1st Qu.:4.000   1st Qu.:120.8   1st Qu.: 96.5  \n Median :19.20   Median :6.000   Median :196.3   Median :123.0  \n Mean   :20.09   Mean   :6.188   Mean   :230.7   Mean   :146.7  \n 3rd Qu.:22.80   3rd Qu.:8.000   3rd Qu.:326.0   3rd Qu.:180.0  \n Max.   :33.90   Max.   :8.000   Max.   :472.0   Max.   :335.0  \n      drat             wt             qsec             vs        \n Min.   :2.760   Min.   :1.513   Min.   :14.50   Min.   :0.0000  \n 1st Qu.:3.080   1st Qu.:2.581   1st Qu.:16.89   1st Qu.:0.0000  \n Median :3.695   Median :3.325   Median :17.71   Median :0.0000  \n Mean   :3.597   Mean   :3.217   Mean   :17.85   Mean   :0.4375  \n 3rd Qu.:3.920   3rd Qu.:3.610   3rd Qu.:18.90   3rd Qu.:1.0000  \n Max.   :4.930   Max.   :5.424   Max.   :22.90   Max.   :1.0000  \n       am              gear            carb      \n Min.   :0.0000   Min.   :3.000   Min.   :1.000  \n 1st Qu.:0.0000   1st Qu.:3.000   1st Qu.:2.000  \n Median :0.0000   Median :4.000   Median :2.000  \n Mean   :0.4062   Mean   :3.688   Mean   :2.812  \n 3rd Qu.:1.0000   3rd Qu.:4.000   3rd Qu.:4.000  \n Max.   :1.0000   Max.   :5.000   Max.   :8.000  \n\n1 + 1\n\n[1] 2"
  },
  {
    "objectID": "Six-Sigma-Projects/six-sigma-projects-2.html",
    "href": "Six-Sigma-Projects/six-sigma-projects-2.html",
    "title": "Six Sigma Projects",
    "section": "",
    "text": "About this site"
  }
]